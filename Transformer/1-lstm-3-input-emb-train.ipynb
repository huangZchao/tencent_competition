{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# set device GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tf.test.is_gpu_available()\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from config import *\n",
    "\n",
    "from tools import *\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_NAME = ['ad_id', 'product_id', 'advertiser_id']\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_user_log = pd.read_pickle(TRAIN_DIR+USER_LOG_PATH)\n",
    "# ts_user_log = pd.read_pickle(TEST_DIR+USER_LOG_PATH)\n",
    "\n",
    "# tr_ad_id_log = pd.read_pickle(TRAIN_DIR+AD_INFO_PATH)\n",
    "# ts_ad_id_log = pd.read_pickle(TEST_DIR+AD_INFO_PATH)\n",
    "\n",
    "# tr_df = pd.concat([tr_user_log, tr_ad_id_log], axis=1)\n",
    "# ts_df = pd.concat([ts_user_log, ts_ad_id_log], axis=1)\n",
    "\n",
    "# tr_df = tr_df[['user_id', 'age', 'gender', 'ad_id', 'product_id', 'advertiser_id', 'click_times']]\n",
    "# ts_df = ts_df[['user_id', 'ad_id', 'product_id', 'advertiser_id', 'click_times']]\n",
    "\n",
    "# tr_df['age'] = tr_df['age'] - 1\n",
    "# tr_df['gender'] = tr_df['gender'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入gensim预训练词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sizes = []\n",
    "wv_matrixes = []\n",
    "for col in COLS_NAME:\n",
    "    #load w2v matrix\n",
    "    f = open(TRAIN_DIR+'gensim_%s_dict.js'%col,'r')\n",
    "    a = f.read()\n",
    "    vocab_dict = eval(a)\n",
    "    f.close()\n",
    "    filter_keys = set(vocab_dict.keys())\n",
    "    vocab_size = len(filter_keys) + 1\n",
    "\n",
    "    wv_matrix = np.load(TRAIN_DIR+'gensim_%s.npy'%col)\n",
    "    row = np.random.uniform(size=(1, wv_matrix.shape[1]))\n",
    "\n",
    "    wv_matrix = np.concatenate([row, wv_matrix], axis=0)\n",
    "\n",
    "#     ### process and get click list\n",
    "#     tr_df[col] = tr_df[col].astype(str)\n",
    "#     ts_df[col] = ts_df[col].astype(str)\n",
    "\n",
    "#     tr_df = tr_df[tr_df[col].isin(filter_keys)]\n",
    "#     ts_df = ts_df[ts_df[col].isin(filter_keys)]\n",
    "\n",
    "#     tr_df[col] = tr_df[col].map(lambda x: vocab_dict[x]) + 1\n",
    "#     ts_df[col] = ts_df[col].map(lambda x: vocab_dict[x]) + 1\n",
    "    \n",
    "    vocab_sizes.append(vocab_size)\n",
    "    wv_matrixes.append(wv_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取点击列表和对应的广告信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_clk_list(df):\n",
    "#     return list(df.values)\n",
    "\n",
    "# tr_df = tr_df.groupby(['user_id']).agg({'age': 'first', \n",
    "#                                         'gender': 'first', \n",
    "#                                         'click_times': lambda x: get_clk_list(x), \n",
    "#                                         'ad_id': lambda x: get_clk_list(x),\n",
    "#                                         'product_id': lambda x: get_clk_list(x),\n",
    "#                                         'advertiser_id': lambda x: get_clk_list(x)}).reset_index()\n",
    "\n",
    "# ts_df = ts_df.groupby(['user_id']).agg({'click_times': lambda x: get_clk_list(x), \n",
    "#                                         'ad_id': lambda x: get_clk_list(x),\n",
    "#                                         'product_id': lambda x: get_clk_list(x),\n",
    "#                                         'advertiser_id': lambda x: get_clk_list(x)}).reset_index()\n",
    "\n",
    "# tr_df.to_pickle('/home/baode/huangzc/tencent/data/train_preliminary/3shuru.pkl')\n",
    "\n",
    "# ts_df.to_pickle('/home/baode/huangzc/tencent/data/test/3shuru.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df = pd.read_pickle('/home/baode/huangzc/tencent/data/train_preliminary/3shuru.pkl')\n",
    "ts_df = pd.read_pickle('/home/baode/huangzc/tencent/data/test/3shuru.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切分 train 和 test 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(tr_df)) <= 0.8\n",
    "vl_df = tr_df[~msk]\n",
    "tr_df = tr_df[msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 128\n",
    "\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding 和mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len:  65\n"
     ]
    }
   ],
   "source": [
    "### cut lenght and pad sequence\n",
    "sentence_size = int(min(tr_df['ad_id'].map(lambda x: len(x)).quantile(0.90), ts_df['ad_id'].map(lambda x: len(x)).quantile(0.99)))\n",
    "print('max len: ', sentence_size)\n",
    "\n",
    "### pad or trunc\n",
    "def pad_or_trunc(t):\n",
    "    dim = tf.size(t)\n",
    "    return tf.cond(tf.equal(dim, sentence_size), lambda: t,\n",
    "                    lambda: tf.cond(tf.greater(dim, sentence_size), lambda: tf.slice(t, [0], [sentence_size]), \n",
    "                                     lambda: tf.concat([t, tf.zeros(dtype=tf.int64, shape=sentence_size-dim)], 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "### make train dataset\n",
    "def gen():\n",
    "    for row in tr_df.itertuples():\n",
    "        ad_id_li, product_id_li, advertiser_id_li, age, gender = getattr(row, COLS_NAME[0]),\\\n",
    "                                                                         getattr(row, COLS_NAME[1]),\\\n",
    "                                                                         getattr(row, COLS_NAME[2]),\\\n",
    "                                                                         getattr(row, 'age'), \\\n",
    "                                                                         getattr(row, 'gender')\n",
    "\n",
    "        yield (ad_id_li, product_id_li, advertiser_id_li, (age, gender))\n",
    "\n",
    "tr_ds = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     (tf.int64, tf.int64, tf.int64, (tf.int64, tf.int64)), \n",
    "     (tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), (tf.TensorShape([]), tf.TensorShape([]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "### make valid dataset\n",
    "def gen():\n",
    "    for row in vl_df.itertuples():\n",
    "        ad_id_li, product_id_li, advertiser_id_li, age, gender = getattr(row, COLS_NAME[0]),\\\n",
    "                                                                         getattr(row, COLS_NAME[1]),\\\n",
    "                                                                         getattr(row, COLS_NAME[2]),\\\n",
    "                                                                         getattr(row, 'age'), \\\n",
    "                                                                         getattr(row, 'gender')\n",
    "\n",
    "        yield (ad_id_li, product_id_li, advertiser_id_li, (age, gender))\n",
    "\n",
    "vl_ds = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     (tf.int64, tf.int64, tf.int64, (tf.int64, tf.int64)), \n",
    "     (tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), (tf.TensorShape([]), tf.TensorShape([]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "### make test dataset\n",
    "def gen():\n",
    "    for row in ts_df.itertuples():\n",
    "        ad_id_li, product_id_li, advertiser_id_li = getattr(row, COLS_NAME[0]),\\\n",
    "                                                             getattr(row, COLS_NAME[1]),\\\n",
    "                                                             getattr(row, COLS_NAME[2])\n",
    "        yield (ad_id_li, product_id_li, advertiser_id_li)\n",
    "\n",
    "ts_ds = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     (tf.int64, tf.int64, tf.int64), \n",
    "     (tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op CacheDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ShuffleDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op BatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "tr_ds = tr_ds.map(lambda ad, product, advertiser, pair: (pad_or_trunc(ad), \n",
    "                                                          pad_or_trunc(product), \n",
    "                                                          pad_or_trunc(advertiser), \n",
    "                                                          pair), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "tr_ds = tr_ds.cache()\n",
    "tr_ds = tr_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "tr_ds = tr_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "vl_ds = vl_ds.map(lambda ad, product, advertiser, pair: (pad_or_trunc(ad), \n",
    "                                                          pad_or_trunc(product), \n",
    "                                                          pad_or_trunc(advertiser), \n",
    "                                                          pair), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "vl_ds = vl_ds.cache()\n",
    "vl_ds = vl_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "vl_ds = vl_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ts_ds = ts_ds.map(lambda ad, product, advertiser: (pad_or_trunc(ad), \n",
    "                                                    pad_or_trunc(product), \n",
    "                                                    pad_or_trunc(advertiser)), num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化器和学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# with tf.device('/gpu:6'):\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, d_model, input_vocab_size, \n",
    "                 weights=None,\n",
    "                 lstm_dims=32,\n",
    "                 dim1=64, dim2=32, num_class1=10, num_class2=2):\n",
    "        '''\n",
    "         d_model: dimension of embedding;\n",
    "         input_vocab_size: vocab size;\n",
    "         rate: dropout rate;\n",
    "         weights: pre-trained embedding weights;\n",
    "        '''\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.lstms = []\n",
    "        self.embs = []\n",
    "        if weights is  not None:        \n",
    "            for i, _ in enumerate(COLS_NAME):\n",
    "                self.embs.append(tf.keras.layers.Embedding(input_vocab_size[i], \n",
    "                                                           d_model, \n",
    "                                                           embeddings_initializer=tf.keras.initializers.Constant(weights[i])))\n",
    "                self.lstms.append(tf.keras.layers.LSTM(lstm_dims))\n",
    "        else:\n",
    "            for i, _ in enumerate(COLS_NAME):\n",
    "                self.embs.append(tf.keras.layers.Embedding(input_vocab_size[i], \n",
    "                                                           d_model))                \n",
    "                self.lstms.append(tf.keras.layers.LSTM(lstm_dims))         \n",
    "        \n",
    "        self.concat = tf.keras.layers.Concatenate(axis=-1)\n",
    "        self.dense1 = tf.keras.layers.Dense(dim1, activation='relu', name='dense1')\n",
    "        self.dense2 = tf.keras.layers.Dense(dim2, activation='relu', name='dense2')\n",
    "        self.dense3_age = tf.keras.layers.Dense(num_class1, activation='softmax', name='softmax1')\n",
    "        self.dense_gender = tf.keras.layers.Dense(num_class2, activation='softmax', name='softmax2')\n",
    "\n",
    "    def call(self, x):\n",
    "        res = []\n",
    "        for i, (emb, lstm) in enumerate(zip(self.embs, self.lstms)):\n",
    "            e = emb(x[i])\n",
    "            res.append(lstm(e))\n",
    "\n",
    "        x = self.concat(res)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3_age(x), self.dense_gender(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(d_model=d_model,  \n",
    "                input_vocab_size=vocab_sizes,\n",
    "                weights=wv_matrixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test\n",
    "# model((tf.random.uniform((1, 60)), \n",
    "#        tf.random.uniform((1, 60)), \n",
    "#        tf.random.uniform((1, 60)), \n",
    "#        tf.random.uniform((1, 60))), \n",
    "#       training=False,\n",
    "#       mask=tf.random.uniform((1, 1, 1, 60)),       \n",
    "#       attention_mask=tf.random.uniform((1, 1, 1, 60)),\n",
    "#       pool_mask=tf.random.uniform((1,60,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数和metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    pred_age = pred[0]\n",
    "    real_age = real[0]\n",
    "\n",
    "    pred_gender = pred[1]\n",
    "    real_gender = real[1]\n",
    "\n",
    "    loss1 = loss_object(real_age, pred_age)\n",
    "    loss2 = loss_object(real_gender, pred_gender)\n",
    "\n",
    "    loss_ = 0.5*loss1 + 0.5*loss2\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "### train metric\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "age_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "gender_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "### test metric\n",
    "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
    "age_valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n",
    "gender_valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inp)\n",
    "        loss = loss_function(tar, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    age_train_accuracy(tar[0], predictions[0])\n",
    "    gender_train_accuracy(tar[1], predictions[1])\n",
    "\n",
    "@tf.function\n",
    "def valid_step(inp, tar):\n",
    "    predictions = model(inp)\n",
    "    loss = loss_function(tar, predictions)\n",
    "\n",
    "    valid_loss(loss)\n",
    "    age_valid_accuracy(tar[0], predictions[0])\n",
    "    gender_valid_accuracy(tar[1], predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op IteratorGetNextSync in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Qr in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op DiagPart in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sign in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Transpose in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Reshape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ConcatV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "WARNING:tensorflow:From /home/baode/anaconda3/envs/competition-py36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_initialize_variables_5723 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_step_10175 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op DivNoNan in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Epoch 1 Batch 0 Loss 1.5045 Age-Accuracy 0.1055 Gender-Accuracy 0.6055 Time taken for training: 16.03949809074402 secs\n",
      "Epoch 1 Batch 100 Loss 1.4698 Age-Accuracy 0.1547 Gender-Accuracy 0.6373 Time taken for training: 150.54555702209473 secs\n",
      "Epoch 1 Batch 200 Loss 1.4445 Age-Accuracy 0.1827 Gender-Accuracy 0.6404 Time taken for training: 145.48881077766418 secs\n",
      "Epoch 1 Batch 300 Loss 1.4211 Age-Accuracy 0.1951 Gender-Accuracy 0.6481 Time taken for training: 145.39921116828918 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 400 Loss 1.4031 Age-Accuracy 0.2015 Gender-Accuracy 0.6526 Time taken for training: 144.81889820098877 secs\n",
      "Epoch 1 Batch 500 Loss 1.3900 Age-Accuracy 0.2063 Gender-Accuracy 0.6564 Time taken for training: 145.20736980438232 secs\n",
      "Epoch 1 Batch 600 Loss 1.3767 Age-Accuracy 0.2096 Gender-Accuracy 0.6619 Time taken for training: 143.02887535095215 secs\n",
      "Epoch 1 Batch 700 Loss 1.3570 Age-Accuracy 0.2115 Gender-Accuracy 0.6810 Time taken for training: 144.85039401054382 secs\n",
      "Epoch 1 Batch 800 Loss 1.3357 Age-Accuracy 0.2138 Gender-Accuracy 0.7007 Time taken for training: 145.32486391067505 secs\n",
      "Epoch 1 Batch 900 Loss 1.3139 Age-Accuracy 0.2179 Gender-Accuracy 0.7188 Time taken for training: 144.54498767852783 secs\n",
      "Epoch 1 Batch 1000 Loss 1.2940 Age-Accuracy 0.2218 Gender-Accuracy 0.7341 Time taken for training: 143.4481565952301 secs\n",
      "Epoch 1 Batch 1100 Loss 1.2754 Age-Accuracy 0.2257 Gender-Accuracy 0.7473 Time taken for training: 144.48843955993652 secs\n",
      "Epoch 1 Batch 1200 Loss 1.2569 Age-Accuracy 0.2301 Gender-Accuracy 0.7594 Time taken for training: 144.10345721244812 secs\n",
      "Epoch 1 Batch 1300 Loss 1.2396 Age-Accuracy 0.2342 Gender-Accuracy 0.7700 Time taken for training: 143.66809678077698 secs\n",
      "Epoch 1 Batch 1400 Loss 1.2237 Age-Accuracy 0.2384 Gender-Accuracy 0.7797 Time taken for training: 143.8981192111969 secs\n",
      "Epoch 1 Batch 1500 Loss 1.2093 Age-Accuracy 0.2421 Gender-Accuracy 0.7882 Time taken for training: 143.44888830184937 secs\n",
      "Epoch 1 Batch 1600 Loss 1.1961 Age-Accuracy 0.2454 Gender-Accuracy 0.7959 Time taken for training: 141.44917702674866 secs\n",
      "Epoch 1 Batch 1700 Loss 1.1832 Age-Accuracy 0.2494 Gender-Accuracy 0.8027 Time taken for training: 141.92729783058167 secs\n",
      "Epoch 1 Batch 1800 Loss 1.1712 Age-Accuracy 0.2530 Gender-Accuracy 0.8088 Time taken for training: 141.46022748947144 secs\n",
      "Epoch 1 Batch 1900 Loss 1.1594 Age-Accuracy 0.2568 Gender-Accuracy 0.8144 Time taken for training: 142.77963948249817 secs\n",
      "Epoch 1 Batch 2000 Loss 1.1483 Age-Accuracy 0.2607 Gender-Accuracy 0.8195 Time taken for training: 142.27395915985107 secs\n",
      "Epoch 1 Batch 2100 Loss 1.1378 Age-Accuracy 0.2644 Gender-Accuracy 0.8241 Time taken for training: 143.9574339389801 secs\n",
      "Epoch 1 Batch 2200 Loss 1.1280 Age-Accuracy 0.2678 Gender-Accuracy 0.8284 Time taken for training: 144.05792117118835 secs\n",
      "Epoch 1 Batch 2300 Loss 1.1186 Age-Accuracy 0.2714 Gender-Accuracy 0.8324 Time taken for training: 142.17213559150696 secs\n",
      "Epoch 1 Batch 2400 Loss 1.1095 Age-Accuracy 0.2749 Gender-Accuracy 0.8358 Time taken for training: 143.09548902511597 secs\n",
      "Epoch 1 Batch 2500 Loss 1.1009 Age-Accuracy 0.2779 Gender-Accuracy 0.8392 Time taken for training: 142.72066068649292 secs\n",
      "Epoch 1 Batch 2600 Loss 1.0924 Age-Accuracy 0.2815 Gender-Accuracy 0.8424 Time taken for training: 142.40118670463562 secs\n",
      "Epoch 1 Batch 2700 Loss 1.0846 Age-Accuracy 0.2845 Gender-Accuracy 0.8453 Time taken for training: 142.31037664413452 secs\n",
      "Epoch 1 Batch 2800 Loss 1.0771 Age-Accuracy 0.2878 Gender-Accuracy 0.8480 Time taken for training: 141.88549709320068 secs\n",
      "Executing op __inference_train_step_29015 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_valid_step_29989 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_valid_step_34487 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "########################################## valid ################################################\n",
      "Epoch 1 Batch 2808 Loss 0.8759 Age-Accuracy 0.3739 Gender-Accuracy 0.9191           Time taken for validation: 62.45884847640991 secs\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    age_train_accuracy.reset_states()\n",
    "    gender_train_accuracy.reset_states()\n",
    "\n",
    "    '''\n",
    "    inp1: ad_id list;\n",
    "    inp2: product_id list;\n",
    "    inp3: advertiser_id list;\n",
    "    inp4: click_times list;\n",
    "    '''\n",
    "    for (batch, (inp1, inp2, inp3, tar)) in enumerate(tr_ds):\n",
    "        train_step((inp1, inp2, inp3), tar)\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Age-Accuracy {:.4f} Gender-Accuracy {:.4f} Time taken for training: {} secs'\n",
    "                   .format(epoch + 1, batch, train_loss.result(), \n",
    "                           age_train_accuracy.result(), gender_train_accuracy.result(),\n",
    "                          time.time()-start))\n",
    "            start = time.time()\n",
    "            \n",
    "    tmp = time.time()\n",
    "    for inp1, inp2, inp3, tar in vl_ds:\n",
    "        valid_step((inp1, inp2, inp3), tar)    \n",
    "    print('########################################## valid ################################################')\n",
    "    print('Epoch {} Batch {} Loss {:.4f} Age-Accuracy {:.4f} Gender-Accuracy {:.4f} \\\n",
    "          Time taken for validation: {} secs'\n",
    "          .format(epoch + 1, batch, \n",
    "                  valid_loss.result(), age_valid_accuracy.result(), gender_valid_accuracy.result(),\n",
    "                  time.time() - tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
