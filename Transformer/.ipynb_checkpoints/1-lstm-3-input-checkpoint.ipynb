{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# set device GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tf.test.is_gpu_available()\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from config import *\n",
    "\n",
    "from tools import *\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_NAME = ['ad_id', 'product_id', 'advertiser_id']\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_user_log = pd.read_pickle(TRAIN_DIR+USER_LOG_PATH)\n",
    "# ts_user_log = pd.read_pickle(TEST_DIR+USER_LOG_PATH)\n",
    "\n",
    "# tr_ad_id_log = pd.read_pickle(TRAIN_DIR+AD_INFO_PATH)\n",
    "# ts_ad_id_log = pd.read_pickle(TEST_DIR+AD_INFO_PATH)\n",
    "\n",
    "# tr_df = pd.concat([tr_user_log, tr_ad_id_log], axis=1)\n",
    "# ts_df = pd.concat([ts_user_log, ts_ad_id_log], axis=1)\n",
    "\n",
    "# tr_df = tr_df[['user_id', 'age', 'gender', 'ad_id', 'product_id', 'advertiser_id', 'click_times']]\n",
    "# ts_df = ts_df[['user_id', 'ad_id', 'product_id', 'advertiser_id', 'click_times']]\n",
    "\n",
    "# tr_df['age'] = tr_df['age'] - 1\n",
    "# tr_df['gender'] = tr_df['gender'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入gensim预训练词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sizes = []\n",
    "wv_matrixes = []\n",
    "for col in COLS_NAME:\n",
    "    #load w2v matrix\n",
    "    f = open(TRAIN_DIR+'gensim_%s_dict.js'%col,'r')\n",
    "    a = f.read()\n",
    "    vocab_dict = eval(a)\n",
    "    f.close()\n",
    "    filter_keys = set(vocab_dict.keys())\n",
    "    vocab_size = len(filter_keys) + 1\n",
    "\n",
    "    wv_matrix = np.load(TRAIN_DIR+'gensim_%s.npy'%col)\n",
    "    row = np.random.uniform(size=(1, wv_matrix.shape[1]))\n",
    "\n",
    "    wv_matrix = np.concatenate([row, wv_matrix], axis=0)\n",
    "\n",
    "#     ### process and get click list\n",
    "#     tr_df[col] = tr_df[col].astype(str)\n",
    "#     ts_df[col] = ts_df[col].astype(str)\n",
    "\n",
    "#     tr_df = tr_df[tr_df[col].isin(filter_keys)]\n",
    "#     ts_df = ts_df[ts_df[col].isin(filter_keys)]\n",
    "\n",
    "#     tr_df[col] = tr_df[col].map(lambda x: vocab_dict[x]) + 1\n",
    "#     ts_df[col] = ts_df[col].map(lambda x: vocab_dict[x]) + 1\n",
    "    \n",
    "    vocab_sizes.append(vocab_size)\n",
    "    wv_matrixes.append(wv_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取点击列表和对应的广告信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_clk_list(df):\n",
    "#     return list(df.values)\n",
    "\n",
    "# tr_df = tr_df.groupby(['user_id']).agg({'age': 'first', \n",
    "#                                         'gender': 'first', \n",
    "#                                         'click_times': lambda x: get_clk_list(x), \n",
    "#                                         'ad_id': lambda x: get_clk_list(x),\n",
    "#                                         'product_id': lambda x: get_clk_list(x),\n",
    "#                                         'advertiser_id': lambda x: get_clk_list(x)}).reset_index()\n",
    "\n",
    "# ts_df = ts_df.groupby(['user_id']).agg({'click_times': lambda x: get_clk_list(x), \n",
    "#                                         'ad_id': lambda x: get_clk_list(x),\n",
    "#                                         'product_id': lambda x: get_clk_list(x),\n",
    "#                                         'advertiser_id': lambda x: get_clk_list(x)}).reset_index()\n",
    "\n",
    "# tr_df.to_pickle('/home/baode/huangzc/tencent/data/train_preliminary/3shuru.pkl')\n",
    "\n",
    "# ts_df.to_pickle('/home/baode/huangzc/tencent/data/test/3shuru.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df = pd.read_pickle('/home/baode/huangzc/tencent/data/train_preliminary/3shuru.pkl')\n",
    "ts_df = pd.read_pickle('/home/baode/huangzc/tencent/data/test/3shuru.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切分 train 和 test 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(tr_df)) <= 0.8\n",
    "vl_df = tr_df[~msk]\n",
    "tr_df = tr_df[msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 128\n",
    "\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding 和mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len:  65\n"
     ]
    }
   ],
   "source": [
    "### cut lenght and pad sequence\n",
    "sentence_size = int(min(tr_df['ad_id'].map(lambda x: len(x)).quantile(0.90), ts_df['ad_id'].map(lambda x: len(x)).quantile(0.99)))\n",
    "print('max len: ', sentence_size)\n",
    "\n",
    "### pad or trunc\n",
    "def pad_or_trunc(t):\n",
    "    dim = tf.size(t)\n",
    "    return tf.cond(tf.equal(dim, sentence_size), lambda: t,\n",
    "                    lambda: tf.cond(tf.greater(dim, sentence_size), lambda: tf.slice(t, [0], [sentence_size]), \n",
    "                                     lambda: tf.concat([t, tf.zeros(dtype=tf.int64, shape=sentence_size-dim)], 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "### make train dataset\n",
    "def gen():\n",
    "    for row in tr_df.itertuples():\n",
    "        ad_id_li, product_id_li, advertiser_id_li, age, gender = getattr(row, COLS_NAME[0]),\\\n",
    "                                                                         getattr(row, COLS_NAME[1]),\\\n",
    "                                                                         getattr(row, COLS_NAME[2]),\\\n",
    "                                                                         getattr(row, 'age'), \\\n",
    "                                                                         getattr(row, 'gender')\n",
    "\n",
    "        yield (ad_id_li, product_id_li, advertiser_id_li, (age, gender))\n",
    "\n",
    "tr_ds = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     (tf.int64, tf.int64, tf.int64, (tf.int64, tf.int64)), \n",
    "     (tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), (tf.TensorShape([]), tf.TensorShape([]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "### make valid dataset\n",
    "def gen():\n",
    "    for row in vl_df.itertuples():\n",
    "        ad_id_li, product_id_li, advertiser_id_li, age, gender = getattr(row, COLS_NAME[0]),\\\n",
    "                                                                         getattr(row, COLS_NAME[1]),\\\n",
    "                                                                         getattr(row, COLS_NAME[2]),\\\n",
    "                                                                         getattr(row, 'age'), \\\n",
    "                                                                         getattr(row, 'gender')\n",
    "\n",
    "        yield (ad_id_li, product_id_li, advertiser_id_li, (age, gender))\n",
    "\n",
    "vl_ds = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     (tf.int64, tf.int64, tf.int64, (tf.int64, tf.int64)), \n",
    "     (tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), (tf.TensorShape([]), tf.TensorShape([]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "### make test dataset\n",
    "def gen():\n",
    "    for row in ts_df.itertuples():\n",
    "        ad_id_li, product_id_li, advertiser_id_li = getattr(row, COLS_NAME[0]),\\\n",
    "                                                             getattr(row, COLS_NAME[1]),\\\n",
    "                                                             getattr(row, COLS_NAME[2])\n",
    "        yield (ad_id_li, product_id_li, advertiser_id_li)\n",
    "\n",
    "ts_ds = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     (tf.int64, tf.int64, tf.int64), \n",
    "     (tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "tr_ds = tr_ds.map(lambda ad, product, advertiser, pair: (pad_or_trunc(ad), \n",
    "                                                          pad_or_trunc(product), \n",
    "                                                          pad_or_trunc(advertiser), \n",
    "                                                          pair), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "tr_ds = tr_ds.cache()\n",
    "tr_ds = tr_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "tr_ds = tr_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "vl_ds = vl_ds.map(lambda ad, product, advertiser, pair: (pad_or_trunc(ad), \n",
    "                                                          pad_or_trunc(product), \n",
    "                                                          pad_or_trunc(advertiser), \n",
    "                                                          pair), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "vl_ds = vl_ds.cache()\n",
    "vl_ds = vl_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "vl_ds = vl_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ts_ds = ts_ds.map(lambda ad, product, advertiser: (pad_or_trunc(ad), \n",
    "                                                    pad_or_trunc(product), \n",
    "                                                    pad_or_trunc(advertiser)), num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化器和学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "# with tf.device('/gpu:6'):\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, d_model, input_vocab_size, \n",
    "                 weights=None,\n",
    "                 lstm_dims=32,\n",
    "                 dim1=64, dim2=32, num_class1=10, num_class2=2):\n",
    "        '''\n",
    "         d_model: dimension of embedding;\n",
    "         input_vocab_size: vocab size;\n",
    "         rate: dropout rate;\n",
    "         weights: pre-trained embedding weights;\n",
    "        '''\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.lstms = []\n",
    "        self.embs = []\n",
    "        if weights is  not None:        \n",
    "            for i, _ in enumerate(COLS_NAME):\n",
    "                self.embs.append(tf.keras.layers.Embedding(input_vocab_size[i], \n",
    "                                                           d_model, \n",
    "                                                           embeddings_initializer=tf.keras.initializers.Constant(weights[i]),\n",
    "                                                           trainable=False))\n",
    "                self.lstms.append(tf.keras.layers.LSTM(lstm_dims))\n",
    "        else:\n",
    "            for i, _ in enumerate(COLS_NAME):\n",
    "                self.embs.append(tf.keras.layers.Embedding(input_vocab_size[i], \n",
    "                                                           d_model))                \n",
    "                self.lstms.append(tf.keras.layers.LSTM(lstm_dims))         \n",
    "        \n",
    "        self.concat = tf.keras.layers.Concatenate(axis=-1)\n",
    "        self.dense1 = tf.keras.layers.Dense(dim1, activation='relu', name='dense1')\n",
    "        self.dense2 = tf.keras.layers.Dense(dim2, activation='relu', name='dense2')\n",
    "        self.dense3_age = tf.keras.layers.Dense(num_class1, activation='softmax', name='softmax1')\n",
    "        self.dense_gender = tf.keras.layers.Dense(num_class2, activation='softmax', name='softmax2')\n",
    "\n",
    "    def call(self, x):\n",
    "        res = []\n",
    "        for i, (emb, lstm) in enumerate(zip(self.embs, self.lstms)):\n",
    "            e = emb(x[i])\n",
    "            res.append(lstm(e))\n",
    "\n",
    "        x = self.concat(res)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3_age(x), self.dense_gender(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(d_model=d_model,  \n",
    "                input_vocab_size=vocab_sizes,\n",
    "                weights=wv_matrixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test\n",
    "# model((tf.random.uniform((1, 60)), \n",
    "#        tf.random.uniform((1, 60)), \n",
    "#        tf.random.uniform((1, 60)), \n",
    "#        tf.random.uniform((1, 60))), \n",
    "#       training=False,\n",
    "#       mask=tf.random.uniform((1, 1, 1, 60)),       \n",
    "#       attention_mask=tf.random.uniform((1, 1, 1, 60)),\n",
    "#       pool_mask=tf.random.uniform((1,60,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数和metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    pred_age = pred[0]\n",
    "    real_age = real[0]\n",
    "\n",
    "    pred_gender = pred[1]\n",
    "    real_gender = real[1]\n",
    "\n",
    "    loss1 = loss_object(real_age, pred_age)\n",
    "    loss2 = loss_object(real_gender, pred_gender)\n",
    "\n",
    "    loss_ = 0.5*loss1 + 0.5*loss2\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "### train metric\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "age_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "gender_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "### test metric\n",
    "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
    "age_valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n",
    "gender_valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inp)\n",
    "        loss = loss_function(tar, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    age_train_accuracy(tar[0], predictions[0])\n",
    "    gender_train_accuracy(tar[1], predictions[1])\n",
    "\n",
    "@tf.function\n",
    "def valid_step(inp, tar):\n",
    "    predictions = model(inp)\n",
    "    loss = loss_function(tar, predictions)\n",
    "\n",
    "    valid_loss(loss)\n",
    "    age_valid_accuracy(tar[0], predictions[0])\n",
    "    gender_valid_accuracy(tar[1], predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_initialize_variables_18015 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_step_22361 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Epoch 1 Batch 0 Loss 1.5482 Age-Accuracy 0.0352 Gender-Accuracy 0.3789 Time taken for training: 7.868388414382935 secs\n",
      "Epoch 1 Batch 100 Loss 1.5003 Age-Accuracy 0.1223 Gender-Accuracy 0.3996 Time taken for training: 28.35895824432373 secs\n",
      "Epoch 1 Batch 200 Loss 1.4599 Age-Accuracy 0.1666 Gender-Accuracy 0.5118 Time taken for training: 27.550350189208984 secs\n",
      "Epoch 1 Batch 300 Loss 1.4371 Age-Accuracy 0.1825 Gender-Accuracy 0.5564 Time taken for training: 27.60918688774109 secs\n",
      "Epoch 1 Batch 400 Loss 1.4203 Age-Accuracy 0.1909 Gender-Accuracy 0.5831 Time taken for training: 27.610395193099976 secs\n",
      "Epoch 1 Batch 500 Loss 1.4058 Age-Accuracy 0.1976 Gender-Accuracy 0.6005 Time taken for training: 27.539262056350708 secs\n",
      "Epoch 1 Batch 600 Loss 1.3908 Age-Accuracy 0.2020 Gender-Accuracy 0.6141 Time taken for training: 27.362475872039795 secs\n",
      "Epoch 1 Batch 700 Loss 1.3725 Age-Accuracy 0.2052 Gender-Accuracy 0.6333 Time taken for training: 27.633454084396362 secs\n",
      "Epoch 1 Batch 800 Loss 1.3543 Age-Accuracy 0.2074 Gender-Accuracy 0.6529 Time taken for training: 27.554627418518066 secs\n",
      "Epoch 1 Batch 900 Loss 1.3360 Age-Accuracy 0.2099 Gender-Accuracy 0.6712 Time taken for training: 27.626288175582886 secs\n",
      "Epoch 1 Batch 1000 Loss 1.3184 Age-Accuracy 0.2128 Gender-Accuracy 0.6880 Time taken for training: 28.169059991836548 secs\n",
      "Epoch 1 Batch 1100 Loss 1.3024 Age-Accuracy 0.2148 Gender-Accuracy 0.7035 Time taken for training: 27.74412775039673 secs\n",
      "Epoch 1 Batch 1200 Loss 1.2861 Age-Accuracy 0.2179 Gender-Accuracy 0.7175 Time taken for training: 27.897581815719604 secs\n",
      "Epoch 1 Batch 1300 Loss 1.2705 Age-Accuracy 0.2216 Gender-Accuracy 0.7298 Time taken for training: 27.64821481704712 secs\n",
      "Epoch 1 Batch 1400 Loss 1.2554 Age-Accuracy 0.2255 Gender-Accuracy 0.7412 Time taken for training: 27.64798355102539 secs\n",
      "Epoch 1 Batch 1500 Loss 1.2411 Age-Accuracy 0.2293 Gender-Accuracy 0.7517 Time taken for training: 28.01897644996643 secs\n",
      "Epoch 1 Batch 1600 Loss 1.2274 Age-Accuracy 0.2328 Gender-Accuracy 0.7613 Time taken for training: 27.825722455978394 secs\n",
      "Epoch 1 Batch 1700 Loss 1.2138 Age-Accuracy 0.2369 Gender-Accuracy 0.7699 Time taken for training: 28.20922064781189 secs\n",
      "Epoch 1 Batch 1800 Loss 1.2009 Age-Accuracy 0.2409 Gender-Accuracy 0.7779 Time taken for training: 28.353559494018555 secs\n",
      "Epoch 1 Batch 1900 Loss 1.1885 Age-Accuracy 0.2448 Gender-Accuracy 0.7851 Time taken for training: 27.411396265029907 secs\n",
      "Epoch 1 Batch 2000 Loss 1.1765 Age-Accuracy 0.2490 Gender-Accuracy 0.7916 Time taken for training: 27.90768027305603 secs\n",
      "Epoch 1 Batch 2100 Loss 1.1655 Age-Accuracy 0.2527 Gender-Accuracy 0.7976 Time taken for training: 28.436087369918823 secs\n",
      "Epoch 1 Batch 2200 Loss 1.1546 Age-Accuracy 0.2566 Gender-Accuracy 0.8031 Time taken for training: 27.96880865097046 secs\n",
      "Epoch 1 Batch 2300 Loss 1.1444 Age-Accuracy 0.2605 Gender-Accuracy 0.8081 Time taken for training: 28.58586597442627 secs\n",
      "Epoch 1 Batch 2400 Loss 1.1346 Age-Accuracy 0.2644 Gender-Accuracy 0.8125 Time taken for training: 27.977221488952637 secs\n",
      "Epoch 1 Batch 2500 Loss 1.1253 Age-Accuracy 0.2681 Gender-Accuracy 0.8168 Time taken for training: 28.231779098510742 secs\n",
      "Epoch 1 Batch 2600 Loss 1.1163 Age-Accuracy 0.2716 Gender-Accuracy 0.8207 Time taken for training: 29.48998522758484 secs\n",
      "Epoch 1 Batch 2700 Loss 1.1077 Age-Accuracy 0.2751 Gender-Accuracy 0.8245 Time taken for training: 28.247808694839478 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 2800 Loss 1.0996 Age-Accuracy 0.2783 Gender-Accuracy 0.8280 Time taken for training: 28.582879781723022 secs\n",
      "Executing op __inference_train_step_41115 in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    age_train_accuracy.reset_states()\n",
    "    gender_train_accuracy.reset_states()\n",
    "\n",
    "    '''\n",
    "    inp1: ad_id list;\n",
    "    inp2: product_id list;\n",
    "    inp3: advertiser_id list;\n",
    "    inp4: click_times list;\n",
    "    '''\n",
    "    for (batch, (inp1, inp2, inp3, tar)) in enumerate(tr_ds):\n",
    "        train_step((inp1, inp2, inp3), tar)\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Age-Accuracy {:.4f} Gender-Accuracy {:.4f} Time taken for training: {} secs'\n",
    "                   .format(epoch + 1, batch, train_loss.result(), \n",
    "                           age_train_accuracy.result(), gender_train_accuracy.result(),\n",
    "                          time.time()-start))\n",
    "            start = time.time()\n",
    "            \n",
    "    tmp = time.time()\n",
    "    for inp1, inp2, inp3, tar in vl_ds:\n",
    "        valid_step((inp1, inp2, inp3), tar)    \n",
    "    print('########################################## valid ################################################')\n",
    "    print('Epoch {} Batch {} Loss {:.4f} Age-Accuracy {:.4f} Gender-Accuracy {:.4f} \\\n",
    "          Time taken for validation: {} secs'\n",
    "          .format(epoch + 1, batch, \n",
    "                  valid_loss.result(), age_valid_accuracy.result(), gender_valid_accuracy.result(),\n",
    "                  time.time() - tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op __inference_valid_step_42089 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_valid_step_46562 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "########################################## valid ################################################\n",
      "Epoch 1 Batch 2812 Loss 0.8766 Age-Accuracy 0.3721 Gender-Accuracy 0.9217       Time taken for validation: 59.73349046707153 secs\n"
     ]
    }
   ],
   "source": [
    "tmp = time.time()\n",
    "for inp1, inp2, inp3, tar in vl_ds:\n",
    "    valid_step((inp1, inp2, inp3), tar)    \n",
    "print('########################################## valid ################################################')\n",
    "print('Epoch {} Batch {} Loss {:.4f} Age-Accuracy {:.4f} Gender-Accuracy {:.4f} \\\n",
    "      Time taken for validation: {} secs'\n",
    "      .format(epoch + 1, batch, \n",
    "              valid_loss.result(), age_valid_accuracy.result(), gender_valid_accuracy.result(),\n",
    "              time.time() - tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing op __inference_valid_step_42089 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
    "Executing op __inference_valid_step_46562 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
    "########################################## valid ################################################\n",
    "Epoch 1 Batch 2812 Loss 0.8766 Age-Accuracy 0.3721 Gender-Accuracy 0.9217       Time taken for validation: 59.73349046707153 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
