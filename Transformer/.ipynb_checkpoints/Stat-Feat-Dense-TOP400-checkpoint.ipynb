{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# set device GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tf.test.is_gpu_available()\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from config import *\n",
    "\n",
    "from tools import *\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 载入统计数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_age_tr = pd.read_pickle(TRAIN_DIR+'feat-impor-age-value.pkl')\n",
    "stat_age_ts = pd.read_pickle(TEST_DIR+'feat-impor-age-value.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_gender_tr = pd.read_pickle(TRAIN_DIR+'feat-impor-gender-value.pkl')\n",
    "stat_gender_ts = pd.read_pickle(TEST_DIR+'feat-impor-gender-value.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(set(stat_age_tr.columns) & set(stat_gender_tr.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_gender_tr = stat_gender_tr.drop(cols, axis=1)\n",
    "stat_gender_ts = stat_gender_ts.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_tr = pd.concat([stat_age_tr, stat_gender_tr], axis=1)\n",
    "stat_ts = pd.concat([stat_age_ts, stat_gender_ts], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_user_log = pd.read_pickle(TRAIN_DIR+USER_LOG_PATH).groupby(['user_id']).agg({'age': 'first', 'gender': 'first'})\n",
    "\n",
    "tr_user_log['age'] = tr_user_log['age'] - 1\n",
    "tr_user_log['gender'] = tr_user_log['gender'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切分 train 和 test 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(tr_df)) <= 0.8\n",
    "vl_df = tr_df[~msk]\n",
    "tr_df = tr_df[msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding 和mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cut lenght and pad sequence\n",
    "sentence_size = int(min(tr_df['ad_id'].map(lambda x: len(x)).quantile(0.90), ts_df['ad_id'].map(lambda x: len(x)).quantile(0.99)))\n",
    "print('max len: ', sentence_size)\n",
    "\n",
    "### pad or trunc\n",
    "def pad_or_trunc(t):\n",
    "    dim = tf.size(t)\n",
    "    return tf.cond(tf.equal(dim, sentence_size), lambda: t,\n",
    "                    lambda: tf.cond(tf.greater(dim, sentence_size), lambda: tf.slice(t, [0], [sentence_size]), \n",
    "                                     lambda: tf.concat([t, tf.zeros(dtype=tf.int64, shape=sentence_size-dim)], 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make train dataset\n",
    "def gen():\n",
    "    for row in tr_df.itertuples():\n",
    "        ad_id_li, product_id_li, advertiser_id_li, age, gender = getattr(row, COLS_NAME[0]),\\\n",
    "                                                                         getattr(row, COLS_NAME[1]),\\\n",
    "                                                                         getattr(row, COLS_NAME[2]),\\\n",
    "                                                                         getattr(row, 'age'), \\\n",
    "                                                                         getattr(row, 'gender')\n",
    "\n",
    "        yield (ad_id_li, product_id_li, advertiser_id_li, (age, gender))\n",
    "\n",
    "tr_ds = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     (tf.int64, tf.int64, tf.int64, (tf.int64, tf.int64)), \n",
    "     (tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), (tf.TensorShape([]), tf.TensorShape([]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make valid dataset\n",
    "def gen():\n",
    "    for row in vl_df.itertuples():\n",
    "        ad_id_li, product_id_li, advertiser_id_li, age, gender = getattr(row, COLS_NAME[0]),\\\n",
    "                                                                         getattr(row, COLS_NAME[1]),\\\n",
    "                                                                         getattr(row, COLS_NAME[2]),\\\n",
    "                                                                         getattr(row, 'age'), \\\n",
    "                                                                         getattr(row, 'gender')\n",
    "\n",
    "        yield (ad_id_li, product_id_li, advertiser_id_li, (age, gender))\n",
    "\n",
    "vl_ds = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     (tf.int64, tf.int64, tf.int64, (tf.int64, tf.int64)), \n",
    "     (tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), (tf.TensorShape([]), tf.TensorShape([]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make test dataset\n",
    "def gen():\n",
    "    for row in ts_df.itertuples():\n",
    "        ad_id_li, product_id_li, advertiser_id_li = getattr(row, COLS_NAME[0]),\\\n",
    "                                                             getattr(row, COLS_NAME[1]),\\\n",
    "                                                             getattr(row, COLS_NAME[2])\n",
    "        yield (ad_id_li, product_id_li, advertiser_id_li)\n",
    "\n",
    "ts_ds = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     (tf.int64, tf.int64, tf.int64), \n",
    "     (tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ds = tr_ds.map(lambda ad, product, advertiser, pair: (pad_or_trunc(ad), \n",
    "                                                          pad_or_trunc(product), \n",
    "                                                          pad_or_trunc(advertiser), \n",
    "                                                          pair), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "tr_ds = tr_ds.cache()\n",
    "tr_ds = tr_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "tr_ds = tr_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "vl_ds = vl_ds.map(lambda ad, product, advertiser, pair: (pad_or_trunc(ad), \n",
    "                                                          pad_or_trunc(product), \n",
    "                                                          pad_or_trunc(advertiser), \n",
    "                                                          pair), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "vl_ds = vl_ds.cache()\n",
    "vl_ds = vl_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "vl_ds = vl_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ts_ds = ts_ds.map(lambda ad, product, advertiser: (pad_or_trunc(ad), \n",
    "                                                    pad_or_trunc(product), \n",
    "                                                    pad_or_trunc(advertiser)), num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化器和学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/gpu:6'):\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, d_model, input_vocab_size, \n",
    "                 weights=None,\n",
    "                 lstm_dims=32,\n",
    "                 dim1=64, dim2=32, num_class1=10, num_class2=2):\n",
    "        '''\n",
    "         d_model: dimension of embedding;\n",
    "         input_vocab_size: vocab size;\n",
    "         rate: dropout rate;\n",
    "         weights: pre-trained embedding weights;\n",
    "        '''\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.lstms = []\n",
    "        self.embs = []\n",
    "        if weights is  not None:        \n",
    "            for i, _ in enumerate(COLS_NAME):\n",
    "                self.embs.append(tf.keras.layers.Embedding(input_vocab_size[i], \n",
    "                                                           d_model, \n",
    "                                                           embeddings_initializer=tf.keras.initializers.Constant(weights[i]),\n",
    "                                                           trainable=False))\n",
    "                self.lstms.append(tf.keras.layers.LSTM(lstm_dims))\n",
    "        else:\n",
    "            for i, _ in enumerate(COLS_NAME):\n",
    "                self.embs.append(tf.keras.layers.Embedding(input_vocab_size[i], \n",
    "                                                           d_model))                \n",
    "                self.lstms.append(tf.keras.layers.LSTM(lstm_dims))         \n",
    "        \n",
    "        self.concat = tf.keras.layers.Concatenate(axis=-1)\n",
    "        self.dense1 = tf.keras.layers.Dense(dim1, activation='relu', name='dense1')\n",
    "        self.dense2 = tf.keras.layers.Dense(dim2, activation='relu', name='dense2')\n",
    "        self.dense3_age = tf.keras.layers.Dense(num_class1, activation='softmax', name='softmax1')\n",
    "        self.dense_gender = tf.keras.layers.Dense(num_class2, activation='softmax', name='softmax2')\n",
    "\n",
    "    def call(self, x):\n",
    "        res = []\n",
    "        for i, (emb, lstm) in enumerate(zip(self.embs, self.lstms)):\n",
    "            e = emb(x[i])\n",
    "            res.append(lstm(e))\n",
    "\n",
    "        x = self.concat(res)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3_age(x), self.dense_gender(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(d_model=d_model,  \n",
    "                input_vocab_size=vocab_sizes,\n",
    "                weights=wv_matrixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test\n",
    "# model((tf.random.uniform((1, 60)), \n",
    "#        tf.random.uniform((1, 60)), \n",
    "#        tf.random.uniform((1, 60)), \n",
    "#        tf.random.uniform((1, 60))), \n",
    "#       training=False,\n",
    "#       mask=tf.random.uniform((1, 1, 1, 60)),       \n",
    "#       attention_mask=tf.random.uniform((1, 1, 1, 60)),\n",
    "#       pool_mask=tf.random.uniform((1,60,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数和metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    pred_age = pred[0]\n",
    "    real_age = real[0]\n",
    "\n",
    "    pred_gender = pred[1]\n",
    "    real_gender = real[1]\n",
    "\n",
    "    loss1 = loss_object(real_age, pred_age)\n",
    "    loss2 = loss_object(real_gender, pred_gender)\n",
    "\n",
    "    loss_ = 0.5*loss1 + 0.5*loss2\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "### train metric\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "age_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "gender_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "### test metric\n",
    "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
    "age_valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n",
    "gender_valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inp)\n",
    "        loss = loss_function(tar, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    age_train_accuracy(tar[0], predictions[0])\n",
    "    gender_train_accuracy(tar[1], predictions[1])\n",
    "\n",
    "@tf.function\n",
    "def valid_step(inp, tar):\n",
    "    predictions = model(inp)\n",
    "    loss = loss_function(tar, predictions)\n",
    "\n",
    "    valid_loss(loss)\n",
    "    age_valid_accuracy(tar[0], predictions[0])\n",
    "    gender_valid_accuracy(tar[1], predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    age_train_accuracy.reset_states()\n",
    "    gender_train_accuracy.reset_states()\n",
    "\n",
    "    '''\n",
    "    inp1: ad_id list;\n",
    "    inp2: product_id list;\n",
    "    inp3: advertiser_id list;\n",
    "    inp4: click_times list;\n",
    "    '''\n",
    "    for (batch, (inp1, inp2, inp3, tar)) in enumerate(tr_ds):\n",
    "        train_step((inp1, inp2, inp3), tar)\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Age-Accuracy {:.4f} Gender-Accuracy {:.4f} Time taken for training: {} secs'\n",
    "                   .format(epoch + 1, batch, train_loss.result(), \n",
    "                           age_train_accuracy.result(), gender_train_accuracy.result(),\n",
    "                          time.time()-start))\n",
    "            start = time.time()\n",
    "            \n",
    "    tmp = time.time()\n",
    "    for inp1, inp2, inp3, tar in vl_ds:\n",
    "        valid_step((inp1, inp2, inp3), tar)    \n",
    "    print('########################################## valid ################################################')\n",
    "    print('Epoch {} Batch {} Loss {:.4f} Age-Accuracy {:.4f} Gender-Accuracy {:.4f} \\\n",
    "          Time taken for validation: {} secs'\n",
    "          .format(epoch + 1, batch, \n",
    "                  valid_loss.result(), age_valid_accuracy.result(), gender_valid_accuracy.result(),\n",
    "                  time.time() - tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = time.time()\n",
    "for inp1, inp2, inp3, tar in vl_ds:\n",
    "    valid_step((inp1, inp2, inp3), tar)    \n",
    "print('########################################## valid ################################################')\n",
    "print('Epoch {} Batch {} Loss {:.4f} Age-Accuracy {:.4f} Gender-Accuracy {:.4f} \\\n",
    "      Time taken for validation: {} secs'\n",
    "      .format(epoch + 1, batch, \n",
    "              valid_loss.result(), age_valid_accuracy.result(), gender_valid_accuracy.result(),\n",
    "              time.time() - tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing op __inference_valid_step_42089 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
    "Executing op __inference_valid_step_46562 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
    "########################################## valid ################################################\n",
    "Epoch 1 Batch 2812 Loss 0.8766 Age-Accuracy 0.3721 Gender-Accuracy 0.9217       Time taken for validation: 59.73349046707153 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
