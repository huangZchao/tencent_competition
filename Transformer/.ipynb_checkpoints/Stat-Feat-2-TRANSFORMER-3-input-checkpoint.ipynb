{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# set device GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tf.test.is_gpu_available()\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from config import *\n",
    "\n",
    "from tools import *\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 2\n",
    "\n",
    "d_model = 128\n",
    "dff = 256\n",
    "num_heads = 4\n",
    "\n",
    "dropout_rate = 0.1\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_NAME = ['creative_id', 'product_category', 'industry', 'time']\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_user_log = pd.read_pickle(TRAIN_DIR+USER_LOG_PATH)\n",
    "# ts_user_log = pd.read_pickle(TEST_DIR+USER_LOG_PATH)\n",
    "\n",
    "# tr_ad_id_log = pd.read_pickle(TRAIN_DIR+AD_INFO_PATH)\n",
    "# ts_ad_id_log = pd.read_pickle(TEST_DIR+AD_INFO_PATH)\n",
    "# del tr_ad_id_log['creative_id'], ts_ad_id_log['creative_id']\n",
    "\n",
    "# tr_df = pd.concat([tr_user_log, tr_ad_id_log], axis=1)\n",
    "# ts_df = pd.concat([ts_user_log, ts_ad_id_log], axis=1)\n",
    "\n",
    "# # tr_df = tr_df[['user_id', 'age', 'gender', 'ad_id', 'product_id', 'advertiser_id', 'click_times']]\n",
    "# # ts_df = ts_df[['user_id', 'ad_id', 'product_id', 'advertiser_id', 'click_times']]\n",
    "\n",
    "# tr_df = tr_df[['user_id', 'creative_id', 'product_category', 'industry', 'time']]\n",
    "# ts_df = ts_df[['user_id', 'creative_id', 'product_category', 'industry', 'time']]\n",
    "\n",
    "# tr_df['age'] = tr_df['age'] - 1\n",
    "# tr_df['gender'] = tr_df['gender'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入gensim预训练词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sizes = []\n",
    "wv_matrixes = []\n",
    "for col in COLS_NAME:\n",
    "    #load w2v matrix\n",
    "    f = open(TRAIN_DIR+'gensim_%s_dict.js'%col,'r')\n",
    "    a = f.read()\n",
    "    vocab_dict = eval(a)\n",
    "    f.close()\n",
    "    filter_keys = set(vocab_dict.keys())\n",
    "    vocab_size = len(filter_keys) + 1\n",
    "\n",
    "    wv_matrix = np.load(TRAIN_DIR+'gensim_%s.npy'%col)\n",
    "    row = np.random.uniform(size=(1, wv_matrix.shape[1]))\n",
    "\n",
    "    wv_matrix = np.concatenate([row, wv_matrix], axis=0)\n",
    "\n",
    "#     ### process and get click list\n",
    "    tr_df[col] = tr_df[col].astype(str)\n",
    "    ts_df[col] = ts_df[col].astype(str)\n",
    "\n",
    "    tr_df = tr_df[tr_df[col].isin(filter_keys)]\n",
    "    ts_df = ts_df[ts_df[col].isin(filter_keys)]\n",
    "\n",
    "    tr_df[col] = tr_df[col].map(lambda x: vocab_dict[x]) + 1\n",
    "    ts_df[col] = ts_df[col].map(lambda x: vocab_dict[x]) + 1\n",
    "    \n",
    "    vocab_sizes.append(vocab_size)\n",
    "    wv_matrixes.append(wv_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取点击列表和对应的广告信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_clk_list(df):\n",
    "#     return list(df.values)\n",
    "\n",
    "# tr_df1 = tr_df.groupby(['user_id']).agg({'creative_id': lambda x: get_clk_list(x), \n",
    "#                                         'product_category': lambda x: get_clk_list(x),\n",
    "#                                         'industry': lambda x: get_clk_list(x),\n",
    "#                                         'time': lambda x: get_clk_list(x)}).reset_index()\n",
    "\n",
    "# ts_df1 = ts_df.groupby(['user_id']).agg({'creative_id': lambda x: get_clk_list(x), \n",
    "#                                         'product_category': lambda x: get_clk_list(x),\n",
    "#                                         'industry': lambda x: get_clk_list(x),\n",
    "#                                         'time': lambda x: get_clk_list(x)}).reset_index()\n",
    "\n",
    "# tr_df = tr_df.groupby(['user_id']).agg({'age': 'first', \n",
    "#                                         'gender': 'first', \n",
    "#                                         'click_times': lambda x: get_clk_list(x), \n",
    "#                                         'ad_id': lambda x: get_clk_list(x),\n",
    "#                                         'product_id': lambda x: get_clk_list(x),\n",
    "#                                         'advertiser_id': lambda x: get_clk_list(x)}).reset_index()\n",
    "\n",
    "# ts_df = ts_df.groupby(['user_id']).agg({'click_times': lambda x: get_clk_list(x), \n",
    "#                                         'ad_id': lambda x: get_clk_list(x),\n",
    "#                                         'product_id': lambda x: get_clk_list(x),\n",
    "#                                         'advertiser_id': lambda x: get_clk_list(x)}).reset_index()\n",
    "\n",
    "# tr_df.to_pickle('/home/baode/huangzc/tencent/data/train_preliminary/3shuru.pkl')\n",
    "\n",
    "# ts_df.to_pickle('/home/baode/huangzc/tencent/data/test/3shuru.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df1.to_pickle('/home/baode/data1/huangzc/tencent/data/train_preliminary/3shuru1.pkl')\n",
    "ts_df1.to_pickle('/home/baode/data1/huangzc/tencent/data/test/3shuru1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_df = pd.read_pickle('/home/baode/data1/huangzc/tencent/data/train_preliminary/3shuru.pkl')\n",
    "# ts_df = pd.read_pickle('/home/baode/data1/huangzc/tencent/data/test/3shuru.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert tr_df1['user_id'].values.tolist() == tr_df['user_id'].values.tolist()\n",
    "# assert ts_df1['user_id'].values.tolist() == ts_df['user_id'].values.tolist()\n",
    "# del tr_df1['user_id'], ts_df1['user_id']\n",
    "\n",
    "# tr_df = pd.concat([tr_df, tr_df1], axis=1)\n",
    "# ts_df = pd.concat([ts_df, ts_df1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df = tmp1\n",
    "ts_df = tmp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_age_tr = pd.read_pickle(TRAIN_DIR+'feat-impor-age-value.pkl')\n",
    "stat_age_ts = pd.read_pickle(TEST_DIR+'feat-impor-age-value.pkl')\n",
    "\n",
    "stat_gender_tr = pd.read_pickle(TRAIN_DIR+'feat-impor-gender-value.pkl')\n",
    "stat_gender_ts = pd.read_pickle(TEST_DIR+'feat-impor-gender-value.pkl')\n",
    "\n",
    "cols = list(set(stat_age_tr.columns) & set(stat_gender_tr.columns))\n",
    "\n",
    "stat_gender_tr = stat_gender_tr.drop(cols, axis=1)\n",
    "stat_gender_ts = stat_gender_ts.drop(cols, axis=1)\n",
    "\n",
    "stat_tr = pd.concat([stat_age_tr, stat_gender_tr], axis=1)\n",
    "stat_ts = pd.concat([stat_age_ts, stat_gender_ts], axis=1)\n",
    "\n",
    "stat_age_tr = pd.read_pickle(TRAIN_DIR+'feat-impor-age-value.pkl')\n",
    "stat_age_ts = pd.read_pickle(TEST_DIR+'feat-impor-age-value.pkl')\n",
    "\n",
    "stat_gender_tr = pd.read_pickle(TRAIN_DIR+'feat-impor-gender-value.pkl')\n",
    "stat_gender_ts = pd.read_pickle(TEST_DIR+'feat-impor-gender-value.pkl')\n",
    "\n",
    "cols = list(set(stat_age_tr.columns) & set(stat_gender_tr.columns))\n",
    "\n",
    "stat_gender_tr = stat_gender_tr.drop(cols, axis=1)\n",
    "stat_gender_ts = stat_gender_ts.drop(cols, axis=1)\n",
    "\n",
    "stat_tr = pd.concat([stat_age_tr, stat_gender_tr], axis=1)\n",
    "stat_ts = pd.concat([stat_age_ts, stat_gender_ts], axis=1)\n",
    "stat_ts = stat_ts.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切分 train 和 test 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(tr_df)) <= 0.8\n",
    "vl_df = tr_df[~msk]\n",
    "tr_df = tr_df[msk]\n",
    "\n",
    "stat_vl = stat_tr[~msk]\n",
    "stat_tr = stat_tr[msk]\n",
    "stat_vl = stat_vl.values\n",
    "stat_tr = stat_tr.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding 和mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len:  153\n"
     ]
    }
   ],
   "source": [
    "### cut lenght and pad sequence\n",
    "sentence_size = int(min(tr_df['ad_id'].map(lambda x: len(x)).quantile(0.99), ts_df['ad_id'].map(lambda x: len(x)).quantile(0.99)))\n",
    "print('max len: ', sentence_size)\n",
    "\n",
    "### pad or trunc\n",
    "def pad_or_trunc(t):\n",
    "    dim = tf.size(t)\n",
    "    return tf.cond(tf.equal(dim, sentence_size), lambda: t,\n",
    "                    lambda: tf.cond(tf.greater(dim, sentence_size), lambda: tf.slice(t, [0], [sentence_size]), \n",
    "                                     lambda: tf.concat([t, tf.zeros(dtype=tf.int64, shape=sentence_size-dim)], 0)))\n",
    "\n",
    "### padding mask\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # 添加额外的维度来将填充加到\n",
    "    # 注意力对数（logits）。\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "### pool mask\n",
    "def create_pooling_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # 添加额外的维度来将填充加到\n",
    "    # 注意力对数（logits）。\n",
    "    return seq[:, :, tf.newaxis]  # (batch_size, seq_len, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "### make train dataset\n",
    "def gen():\n",
    "    for row, row1 in zip(tr_df.itertuples(), stat_tr):\n",
    "        ad_id_li, product_id_li, advertiser_id_li, clk_li, age, gender = getattr(row, COLS_NAME[0]),\\\n",
    "                                                                         getattr(row, COLS_NAME[1]),\\\n",
    "                                                                         getattr(row, COLS_NAME[2]),\\\n",
    "                                                                         getattr(row, 'click_times'), \\\n",
    "                                                                         getattr(row, 'age'), \\\n",
    "                                                                         getattr(row, 'gender')\n",
    "\n",
    "        yield (row1, ad_id_li, product_id_li, advertiser_id_li, clk_li, (age, gender))\n",
    "\n",
    "tr_ds = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     (tf.float32, tf.int64, tf.int64, tf.int64, tf.int64, (tf.int64, tf.int64)), \n",
    "     (tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), (tf.TensorShape([]), tf.TensorShape([]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "### make valid dataset\n",
    "def gen():\n",
    "    for row, row1 in zip(vl_df.itertuples(), stat_vl):\n",
    "        ad_id_li, product_id_li, advertiser_id_li, clk_li, age, gender = getattr(row, COLS_NAME[0]),\\\n",
    "                                                                         getattr(row, COLS_NAME[1]),\\\n",
    "                                                                         getattr(row, COLS_NAME[2]),\\\n",
    "                                                                         getattr(row, 'click_times'), \\\n",
    "                                                                         getattr(row, 'age'), \\\n",
    "                                                                         getattr(row, 'gender')\n",
    "\n",
    "        yield (row1, ad_id_li, product_id_li, advertiser_id_li, clk_li, (age, gender))\n",
    "\n",
    "vl_ds = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     (tf.float32, tf.int64, tf.int64, tf.int64, tf.int64, (tf.int64, tf.int64)), \n",
    "     (tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), (tf.TensorShape([]), tf.TensorShape([]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "### make test dataset\n",
    "def gen():\n",
    "    for row, row1 in zip(ts_df.itertuples(), stat_ts):\n",
    "        ad_id_li, product_id_li, advertiser_id_li, clk_li = getattr(row, COLS_NAME[0]),\\\n",
    "                                                             getattr(row, COLS_NAME[1]),\\\n",
    "                                                             getattr(row, COLS_NAME[2]),\\\n",
    "                                                             getattr(row, 'click_times')\n",
    "        yield (row1, ad_id_li, product_id_li, advertiser_id_li, clk_li)\n",
    "\n",
    "ts_ds = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     (tf.float32, tf.int64, tf.int64, tf.int64, tf.int64), \n",
    "     (tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "tr_ds = tr_ds.map(lambda stat, ad, product, advertiser, clk_times, pair: (stat,\n",
    "                                                                     pad_or_trunc(ad), \n",
    "                                                                     pad_or_trunc(product), \n",
    "                                                                     pad_or_trunc(advertiser), \n",
    "                                                                     pad_or_trunc(clk_times), \n",
    "                                                                     pair), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "vl_ds = vl_ds.map(lambda stat, ad, product, advertiser, clk_times, pair: (stat,\n",
    "                                                                     pad_or_trunc(ad), \n",
    "                                                                     pad_or_trunc(product), \n",
    "                                                                     pad_or_trunc(advertiser), \n",
    "                                                                     pad_or_trunc(clk_times), \n",
    "                                                                     pair), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ts_ds = ts_ds.map(lambda stat, ad, product, advertiser, clk_times: (stat,\n",
    "                                                               pad_or_trunc(ad), \n",
    "                                                               pad_or_trunc(product), \n",
    "                                                               pad_or_trunc(advertiser), \n",
    "                                                               pad_or_trunc(clk_times)), num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ds = tr_ds.cache()\n",
    "tr_ds = tr_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "tr_ds = tr_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "vl_ds = vl_ds.cache()\n",
    "vl_ds = vl_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "vl_ds = vl_ds.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化器和学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'transformer' from '/home/baode/data1/huangzc/tencent/code/tencent_competition/Transformer/transformer.py'>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformer\n",
    "import imp\n",
    "imp.reload(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransLSTM(tf.keras.layers.Layer):\n",
    "    def __init__(self, n1, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, weights,\n",
    "                  rate):\n",
    "        super(TransLSTM, self).__init__()\n",
    "                  \n",
    "        self.transformer_enc = Encoder(num_layers=n1, \n",
    "                                       d_model=d_model, \n",
    "                                       num_heads=num_heads, \n",
    "                                       dff=dff, \n",
    "                                       input_vocab_size=input_vocab_size,\n",
    "                                       maximum_position_encoding=maximum_position_encoding, \n",
    "                                       rate=rate, \n",
    "                                       weights=weights)\n",
    "        \n",
    "        self.avg_pool = tf.keras.layers.GlobalAveragePooling1D()\n",
    "        \n",
    "    def call(self, inputs, training, mask, attention_mask, pool_mask):\n",
    "        x = inputs\n",
    "        x = self.transformer_enc(x, training, mask, attention_mask)\n",
    "        x *= pool_mask\n",
    "        x = self.avg_pool(x) \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test\n",
    "# temp = TransLSTM(n1=1, d_model=32, num_heads=2, dff=10, input_vocab_size=60, maximum_position_encoding=60, weights=None,\n",
    "#                                             n2=1, lstm_dims=32,\n",
    "#                                             pool_size=2, pool_strides=2,\n",
    "#                                             rate=0.1)\n",
    "\n",
    "# y = tf.random.uniform((1, 60))  # (batch_size, encoder_sequence, d_model)\n",
    "# out = temp(y, training=False, mask=None, attention_mask=None, pool_mask=tf.ones((1,60,1)))\n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, n1, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding,\n",
    "                 rate=0.1, weights=None,\n",
    "                 dim0=256, dim00=128, dim1=64, dim2=32, num_class1=10, num_class2=2):\n",
    "        '''\n",
    "         n1: number of layers in transformer encoder;\n",
    "         n2: number of layers in lstm;\n",
    "         d_model: dimension of embedding;\n",
    "         num_heads: number of heads in multi-head attention;\n",
    "         dff: dimension of feed forward innner layer;\n",
    "         input_vocab_size: vocab size;\n",
    "         max_position_encoding: ;\n",
    "         rate: dropout rate;\n",
    "         weights: pre-trained embedding weights;\n",
    "        '''\n",
    "        super(MyModel, self).__init__()\n",
    "        self.transLSTM = []\n",
    "        if weights is None:\n",
    "            for i, _ in enumerate(COLS_NAME):\n",
    "                self.transLSTM.append(TransLSTM(n1, d_model, num_heads, dff, input_vocab_size[i], maximum_position_encoding[i], \n",
    "                                                weights, rate))\n",
    "        else:\n",
    "            for i, _ in enumerate(COLS_NAME):\n",
    "                self.transLSTM.append(TransLSTM(n1, d_model, num_heads, dff, input_vocab_size[i], maximum_position_encoding[i], \n",
    "                                                weights[i], rate))   \n",
    "                \n",
    "        \n",
    "        self.dense0 = tf.keras.layers.Dense(dim0, activation='relu', name='dense0')\n",
    "        self.dense00 = tf.keras.layers.Dense(dim00, activation='relu', name='dense00')\n",
    "        \n",
    "        self.concat = tf.keras.layers.Concatenate(axis=-1)\n",
    "        self.dense1 = tf.keras.layers.Dense(dim1, activation='relu', name='dense1')\n",
    "        self.dense2 = tf.keras.layers.Dense(dim2, activation='relu', name='dense2')\n",
    "        self.dense3_age = tf.keras.layers.Dense(num_class1, activation='softmax', name='softmax1')\n",
    "        self.dense_gender = tf.keras.layers.Dense(num_class2, activation='softmax', name='softmax2')\n",
    "\n",
    "    def call(self, x, training, mask, attention_mask, pool_mask):\n",
    "        res = []\n",
    "        for i, layer in enumerate(self.transLSTM):\n",
    "            res.append(layer(x[i+1], training, mask, attention_mask, pool_mask))        \n",
    "        res.append(self.dense00(self.dense0(x[0])))\n",
    "        \n",
    "        x = self.concat(res)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3_age(x), self.dense_gender(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(n1=n1, d_model=d_model, num_heads=num_heads, dff=dff, \n",
    "                input_vocab_size=vocab_sizes, maximum_position_encoding=vocab_sizes, \n",
    "                weights=wv_matrixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test\n",
    "# model((tf.random.uniform((1, 60)), \n",
    "#        tf.random.uniform((1, 60)), \n",
    "#        tf.random.uniform((1, 60)), \n",
    "#        tf.random.uniform((1, 60))), \n",
    "#       training=False,\n",
    "#       mask=tf.random.uniform((1, 1, 1, 60)),       \n",
    "#       attention_mask=tf.random.uniform((1, 1, 1, 60)),\n",
    "#       pool_mask=tf.random.uniform((1,60,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数和metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    pred_age = pred[0]\n",
    "    real_age = real[0]\n",
    "\n",
    "    pred_gender = pred[1]\n",
    "    real_gender = real[1]\n",
    "\n",
    "    loss1 = loss_object(real_age, pred_age)\n",
    "    loss2 = loss_object(real_gender, pred_gender)\n",
    "\n",
    "    loss_ = 0.5*loss1 + 0.5*loss2\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "### train metric\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "age_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "gender_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "### test metric\n",
    "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
    "age_valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n",
    "gender_valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "\n",
    "    mask = create_padding_mask(inp[1])\n",
    "    attention_mask = tf.cast(inp[-1][:, tf.newaxis, tf.newaxis, :], tf.float32)\n",
    "    pool_mask = create_pooling_mask(inp[1])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inp, \n",
    "                            training=False, \n",
    "                            mask=mask, \n",
    "                            attention_mask=attention_mask,\n",
    "                            pool_mask=pool_mask\n",
    "                            )\n",
    "        loss = loss_function(tar, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    age_train_accuracy(tar[0], predictions[0])\n",
    "    gender_train_accuracy(tar[1], predictions[1])\n",
    "\n",
    "@tf.function\n",
    "def valid_step(inp, tar):\n",
    "\n",
    "    mask = create_padding_mask(inp[1])\n",
    "    attention_mask = tf.cast(inp[-1][:, tf.newaxis, tf.newaxis, :], tf.float32)\n",
    "    pool_mask = create_pooling_mask(inp[1])\n",
    "\n",
    "    predictions = model(inp, \n",
    "                        training=False, \n",
    "                        mask=mask, \n",
    "                        attention_mask=attention_mask,\n",
    "                        pool_mask=pool_mask\n",
    "                        )\n",
    "    loss = loss_function(tar, predictions)\n",
    "\n",
    "    valid_loss(loss)\n",
    "    age_valid_accuracy(tar[0], predictions[0])\n",
    "    gender_valid_accuracy(tar[1], predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_initialize_variables_40745 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_step_44099 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Epoch 1 Batch 0 Loss 2.5349 Age-Accuracy 0.1250 Gender-Accuracy 0.3594 Time taken for training: 6.946529388427734 secs\n",
      "Epoch 1 Batch 100 Loss 1.9733 Age-Accuracy 0.1530 Gender-Accuracy 0.3604 Time taken for training: 14.694594621658325 secs\n",
      "Epoch 1 Batch 200 Loss 1.6748 Age-Accuracy 0.1884 Gender-Accuracy 0.5390 Time taken for training: 14.751550436019897 secs\n",
      "Epoch 1 Batch 300 Loss 1.4885 Age-Accuracy 0.2223 Gender-Accuracy 0.6590 Time taken for training: 14.795406341552734 secs\n",
      "Epoch 1 Batch 400 Loss 1.3559 Age-Accuracy 0.2529 Gender-Accuracy 0.7236 Time taken for training: 14.820422410964966 secs\n",
      "Epoch 1 Batch 500 Loss 1.2606 Age-Accuracy 0.2781 Gender-Accuracy 0.7637 Time taken for training: 14.8306143283844 secs\n",
      "Epoch 1 Batch 600 Loss 1.1927 Age-Accuracy 0.2975 Gender-Accuracy 0.7899 Time taken for training: 14.835066080093384 secs\n",
      "Epoch 1 Batch 700 Loss 1.1422 Age-Accuracy 0.3127 Gender-Accuracy 0.8091 Time taken for training: 14.847437858581543 secs\n",
      "Epoch 1 Batch 800 Loss 1.1021 Age-Accuracy 0.3252 Gender-Accuracy 0.8240 Time taken for training: 14.84561038017273 secs\n",
      "Epoch 1 Batch 900 Loss 1.0704 Age-Accuracy 0.3358 Gender-Accuracy 0.8354 Time taken for training: 14.85764217376709 secs\n",
      "Epoch 1 Batch 1000 Loss 1.0439 Age-Accuracy 0.3447 Gender-Accuracy 0.8448 Time taken for training: 14.853276252746582 secs\n",
      "Epoch 1 Batch 1100 Loss 1.0222 Age-Accuracy 0.3515 Gender-Accuracy 0.8524 Time taken for training: 14.859680652618408 secs\n",
      "Epoch 1 Batch 1200 Loss 1.0035 Age-Accuracy 0.3577 Gender-Accuracy 0.8589 Time taken for training: 14.862785577774048 secs\n",
      "Epoch 1 Batch 1300 Loss 0.9875 Age-Accuracy 0.3631 Gender-Accuracy 0.8643 Time taken for training: 14.85845160484314 secs\n",
      "Epoch 1 Batch 1400 Loss 0.9736 Age-Accuracy 0.3676 Gender-Accuracy 0.8690 Time taken for training: 14.851460695266724 secs\n",
      "Epoch 1 Batch 1500 Loss 0.9617 Age-Accuracy 0.3716 Gender-Accuracy 0.8730 Time taken for training: 14.854572534561157 secs\n",
      "Epoch 1 Batch 1600 Loss 0.9510 Age-Accuracy 0.3752 Gender-Accuracy 0.8766 Time taken for training: 14.87239146232605 secs\n",
      "Epoch 1 Batch 1700 Loss 0.9411 Age-Accuracy 0.3784 Gender-Accuracy 0.8800 Time taken for training: 14.873987674713135 secs\n",
      "Epoch 1 Batch 1800 Loss 0.9324 Age-Accuracy 0.3815 Gender-Accuracy 0.8829 Time taken for training: 14.873200416564941 secs\n",
      "Epoch 1 Batch 1900 Loss 0.9247 Age-Accuracy 0.3841 Gender-Accuracy 0.8855 Time taken for training: 14.8496253490448 secs\n",
      "Epoch 1 Batch 2000 Loss 0.9174 Age-Accuracy 0.3869 Gender-Accuracy 0.8878 Time taken for training: 14.86176085472107 secs\n",
      "Epoch 1 Batch 2100 Loss 0.9110 Age-Accuracy 0.3893 Gender-Accuracy 0.8898 Time taken for training: 14.859266757965088 secs\n",
      "Epoch 1 Batch 2200 Loss 0.9049 Age-Accuracy 0.3914 Gender-Accuracy 0.8919 Time taken for training: 14.867220163345337 secs\n",
      "Epoch 1 Batch 2300 Loss 0.8993 Age-Accuracy 0.3936 Gender-Accuracy 0.8937 Time taken for training: 14.863143920898438 secs\n",
      "Epoch 1 Batch 2400 Loss 0.8943 Age-Accuracy 0.3956 Gender-Accuracy 0.8953 Time taken for training: 14.860972166061401 secs\n",
      "Epoch 1 Batch 2500 Loss 0.8896 Age-Accuracy 0.3973 Gender-Accuracy 0.8968 Time taken for training: 14.858460426330566 secs\n",
      "Epoch 1 Batch 2600 Loss 0.8852 Age-Accuracy 0.3989 Gender-Accuracy 0.8982 Time taken for training: 14.878626585006714 secs\n",
      "Epoch 1 Batch 2700 Loss 0.8810 Age-Accuracy 0.4004 Gender-Accuracy 0.8996 Time taken for training: 14.86690354347229 secs\n",
      "Epoch 1 Batch 2800 Loss 0.8773 Age-Accuracy 0.4020 Gender-Accuracy 0.9007 Time taken for training: 14.867311239242554 secs\n",
      "Executing op __inference_train_step_67492 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_valid_step_68829 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "########################################## valid ################################################\n",
      "Epoch 1 Batch 2813 Loss 0.7692 Age-Accuracy 0.4451 Gender-Accuracy 0.9319           Time taken for validation: 61.94429135322571 secs\n",
      "Epoch 2 Batch 0 Loss 0.7734 Age-Accuracy 0.4336 Gender-Accuracy 0.9414 Time taken for training: 0.5559308528900146 secs\n",
      "Epoch 2 Batch 100 Loss 0.7694 Age-Accuracy 0.4430 Gender-Accuracy 0.9347 Time taken for training: 14.839223384857178 secs\n",
      "Epoch 2 Batch 200 Loss 0.7737 Age-Accuracy 0.4407 Gender-Accuracy 0.9337 Time taken for training: 14.848973035812378 secs\n",
      "Epoch 2 Batch 300 Loss 0.7726 Age-Accuracy 0.4409 Gender-Accuracy 0.9338 Time taken for training: 14.852253675460815 secs\n",
      "Epoch 2 Batch 400 Loss 0.7724 Age-Accuracy 0.4406 Gender-Accuracy 0.9336 Time taken for training: 14.862773418426514 secs\n",
      "Epoch 2 Batch 500 Loss 0.7722 Age-Accuracy 0.4405 Gender-Accuracy 0.9337 Time taken for training: 14.874502658843994 secs\n",
      "Epoch 2 Batch 600 Loss 0.7724 Age-Accuracy 0.4411 Gender-Accuracy 0.9334 Time taken for training: 14.871976137161255 secs\n",
      "Epoch 2 Batch 700 Loss 0.7730 Age-Accuracy 0.4404 Gender-Accuracy 0.9336 Time taken for training: 14.872563362121582 secs\n",
      "Epoch 2 Batch 800 Loss 0.7724 Age-Accuracy 0.4413 Gender-Accuracy 0.9334 Time taken for training: 14.871364116668701 secs\n",
      "Epoch 2 Batch 900 Loss 0.7724 Age-Accuracy 0.4416 Gender-Accuracy 0.9334 Time taken for training: 14.8783540725708 secs\n",
      "Epoch 2 Batch 1000 Loss 0.7719 Age-Accuracy 0.4421 Gender-Accuracy 0.9336 Time taken for training: 14.875458002090454 secs\n",
      "Epoch 2 Batch 1100 Loss 0.7718 Age-Accuracy 0.4421 Gender-Accuracy 0.9335 Time taken for training: 14.881076574325562 secs\n",
      "Epoch 2 Batch 1200 Loss 0.7716 Age-Accuracy 0.4417 Gender-Accuracy 0.9335 Time taken for training: 14.874416828155518 secs\n",
      "Epoch 2 Batch 1300 Loss 0.7712 Age-Accuracy 0.4422 Gender-Accuracy 0.9335 Time taken for training: 14.881864070892334 secs\n",
      "Epoch 2 Batch 1400 Loss 0.7708 Age-Accuracy 0.4419 Gender-Accuracy 0.9335 Time taken for training: 14.868682384490967 secs\n",
      "Epoch 2 Batch 1500 Loss 0.7708 Age-Accuracy 0.4418 Gender-Accuracy 0.9336 Time taken for training: 14.90740180015564 secs\n",
      "Epoch 2 Batch 1600 Loss 0.7705 Age-Accuracy 0.4418 Gender-Accuracy 0.9337 Time taken for training: 14.867193222045898 secs\n",
      "Epoch 2 Batch 1700 Loss 0.7699 Age-Accuracy 0.4422 Gender-Accuracy 0.9338 Time taken for training: 14.879933595657349 secs\n",
      "Epoch 2 Batch 1800 Loss 0.7694 Age-Accuracy 0.4425 Gender-Accuracy 0.9339 Time taken for training: 14.889521598815918 secs\n",
      "Epoch 2 Batch 1900 Loss 0.7691 Age-Accuracy 0.4426 Gender-Accuracy 0.9340 Time taken for training: 14.8736412525177 secs\n",
      "Epoch 2 Batch 2000 Loss 0.7684 Age-Accuracy 0.4429 Gender-Accuracy 0.9341 Time taken for training: 14.874689817428589 secs\n",
      "Epoch 2 Batch 2100 Loss 0.7680 Age-Accuracy 0.4434 Gender-Accuracy 0.9341 Time taken for training: 14.925650835037231 secs\n",
      "Epoch 2 Batch 2200 Loss 0.7674 Age-Accuracy 0.4435 Gender-Accuracy 0.9343 Time taken for training: 14.872226238250732 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 2300 Loss 0.7669 Age-Accuracy 0.4438 Gender-Accuracy 0.9343 Time taken for training: 14.87080192565918 secs\n",
      "Epoch 2 Batch 2400 Loss 0.7666 Age-Accuracy 0.4440 Gender-Accuracy 0.9344 Time taken for training: 14.97436261177063 secs\n",
      "Epoch 2 Batch 2500 Loss 0.7662 Age-Accuracy 0.4442 Gender-Accuracy 0.9344 Time taken for training: 14.884143114089966 secs\n",
      "Epoch 2 Batch 2600 Loss 0.7657 Age-Accuracy 0.4445 Gender-Accuracy 0.9345 Time taken for training: 14.87522554397583 secs\n",
      "Epoch 2 Batch 2700 Loss 0.7652 Age-Accuracy 0.4447 Gender-Accuracy 0.9346 Time taken for training: 14.998866081237793 secs\n",
      "Epoch 2 Batch 2800 Loss 0.7649 Age-Accuracy 0.4450 Gender-Accuracy 0.9347 Time taken for training: 14.900001049041748 secs\n",
      "########################################## valid ################################################\n",
      "Epoch 2 Batch 2813 Loss 0.7615 Age-Accuracy 0.4499 Gender-Accuracy 0.9328           Time taken for validation: 56.183120012283325 secs\n",
      "Epoch 3 Batch 0 Loss 0.7560 Age-Accuracy 0.4648 Gender-Accuracy 0.9414 Time taken for training: 0.5081899166107178 secs\n",
      "Epoch 3 Batch 100 Loss 0.7475 Age-Accuracy 0.4567 Gender-Accuracy 0.9370 Time taken for training: 14.849216222763062 secs\n",
      "Epoch 3 Batch 200 Loss 0.7524 Age-Accuracy 0.4499 Gender-Accuracy 0.9367 Time taken for training: 14.93989896774292 secs\n",
      "Epoch 3 Batch 300 Loss 0.7514 Age-Accuracy 0.4508 Gender-Accuracy 0.9372 Time taken for training: 14.8723623752594 secs\n",
      "Epoch 3 Batch 400 Loss 0.7518 Age-Accuracy 0.4505 Gender-Accuracy 0.9372 Time taken for training: 14.876266956329346 secs\n",
      "Epoch 3 Batch 500 Loss 0.7509 Age-Accuracy 0.4516 Gender-Accuracy 0.9374 Time taken for training: 14.865871667861938 secs\n",
      "Epoch 3 Batch 600 Loss 0.7508 Age-Accuracy 0.4532 Gender-Accuracy 0.9370 Time taken for training: 14.88449764251709 secs\n",
      "Epoch 3 Batch 700 Loss 0.7516 Age-Accuracy 0.4523 Gender-Accuracy 0.9371 Time taken for training: 14.865036487579346 secs\n",
      "Epoch 3 Batch 800 Loss 0.7509 Age-Accuracy 0.4532 Gender-Accuracy 0.9372 Time taken for training: 14.983774185180664 secs\n",
      "Epoch 3 Batch 900 Loss 0.7504 Age-Accuracy 0.4538 Gender-Accuracy 0.9373 Time taken for training: 14.892167806625366 secs\n",
      "Epoch 3 Batch 1000 Loss 0.7500 Age-Accuracy 0.4542 Gender-Accuracy 0.9374 Time taken for training: 14.896270036697388 secs\n",
      "Epoch 3 Batch 1100 Loss 0.7500 Age-Accuracy 0.4538 Gender-Accuracy 0.9373 Time taken for training: 14.887762069702148 secs\n",
      "Epoch 3 Batch 1200 Loss 0.7495 Age-Accuracy 0.4539 Gender-Accuracy 0.9373 Time taken for training: 14.903638124465942 secs\n",
      "Epoch 3 Batch 1300 Loss 0.7490 Age-Accuracy 0.4545 Gender-Accuracy 0.9374 Time taken for training: 14.879668712615967 secs\n",
      "Epoch 3 Batch 1400 Loss 0.7484 Age-Accuracy 0.4543 Gender-Accuracy 0.9375 Time taken for training: 14.90046739578247 secs\n",
      "Epoch 3 Batch 1500 Loss 0.7483 Age-Accuracy 0.4544 Gender-Accuracy 0.9375 Time taken for training: 14.91796588897705 secs\n",
      "Epoch 3 Batch 1600 Loss 0.7480 Age-Accuracy 0.4544 Gender-Accuracy 0.9375 Time taken for training: 14.906658172607422 secs\n",
      "Epoch 3 Batch 1700 Loss 0.7476 Age-Accuracy 0.4546 Gender-Accuracy 0.9377 Time taken for training: 14.983466148376465 secs\n",
      "Epoch 3 Batch 1800 Loss 0.7473 Age-Accuracy 0.4547 Gender-Accuracy 0.9378 Time taken for training: 14.955442905426025 secs\n",
      "Epoch 3 Batch 1900 Loss 0.7471 Age-Accuracy 0.4546 Gender-Accuracy 0.9379 Time taken for training: 14.905538558959961 secs\n",
      "Epoch 3 Batch 2000 Loss 0.7466 Age-Accuracy 0.4549 Gender-Accuracy 0.9379 Time taken for training: 14.923840284347534 secs\n",
      "Epoch 3 Batch 2100 Loss 0.7462 Age-Accuracy 0.4554 Gender-Accuracy 0.9379 Time taken for training: 14.979761838912964 secs\n",
      "Epoch 3 Batch 2200 Loss 0.7458 Age-Accuracy 0.4555 Gender-Accuracy 0.9380 Time taken for training: 14.916210174560547 secs\n",
      "Epoch 3 Batch 2300 Loss 0.7454 Age-Accuracy 0.4558 Gender-Accuracy 0.9381 Time taken for training: 14.906737804412842 secs\n",
      "Epoch 3 Batch 2400 Loss 0.7454 Age-Accuracy 0.4558 Gender-Accuracy 0.9380 Time taken for training: 14.913790225982666 secs\n",
      "Epoch 3 Batch 2500 Loss 0.7451 Age-Accuracy 0.4559 Gender-Accuracy 0.9381 Time taken for training: 14.931787014007568 secs\n",
      "Epoch 3 Batch 2600 Loss 0.7448 Age-Accuracy 0.4563 Gender-Accuracy 0.9381 Time taken for training: 14.882283926010132 secs\n",
      "Epoch 3 Batch 2700 Loss 0.7445 Age-Accuracy 0.4564 Gender-Accuracy 0.9382 Time taken for training: 14.919954776763916 secs\n",
      "Epoch 3 Batch 2800 Loss 0.7444 Age-Accuracy 0.4565 Gender-Accuracy 0.9383 Time taken for training: 15.017593622207642 secs\n",
      "########################################## valid ################################################\n",
      "Epoch 3 Batch 2813 Loss 0.7545 Age-Accuracy 0.4536 Gender-Accuracy 0.9347           Time taken for validation: 55.40880513191223 secs\n",
      "Epoch 4 Batch 0 Loss 0.7338 Age-Accuracy 0.4648 Gender-Accuracy 0.9414 Time taken for training: 0.5441863536834717 secs\n",
      "Epoch 4 Batch 100 Loss 0.7331 Age-Accuracy 0.4645 Gender-Accuracy 0.9401 Time taken for training: 14.834423303604126 secs\n",
      "Epoch 4 Batch 200 Loss 0.7379 Age-Accuracy 0.4586 Gender-Accuracy 0.9397 Time taken for training: 14.853016138076782 secs\n",
      "Epoch 4 Batch 300 Loss 0.7366 Age-Accuracy 0.4589 Gender-Accuracy 0.9400 Time taken for training: 14.849833011627197 secs\n",
      "Epoch 4 Batch 400 Loss 0.7371 Age-Accuracy 0.4596 Gender-Accuracy 0.9397 Time taken for training: 14.837088584899902 secs\n",
      "Epoch 4 Batch 500 Loss 0.7359 Age-Accuracy 0.4608 Gender-Accuracy 0.9398 Time taken for training: 14.88176155090332 secs\n",
      "Epoch 4 Batch 600 Loss 0.7360 Age-Accuracy 0.4624 Gender-Accuracy 0.9394 Time taken for training: 14.975635051727295 secs\n",
      "Epoch 4 Batch 700 Loss 0.7368 Age-Accuracy 0.4620 Gender-Accuracy 0.9393 Time taken for training: 14.870704412460327 secs\n",
      "Epoch 4 Batch 800 Loss 0.7363 Age-Accuracy 0.4628 Gender-Accuracy 0.9393 Time taken for training: 14.852686405181885 secs\n",
      "Epoch 4 Batch 900 Loss 0.7359 Age-Accuracy 0.4631 Gender-Accuracy 0.9395 Time taken for training: 14.882171869277954 secs\n",
      "Epoch 4 Batch 1000 Loss 0.7356 Age-Accuracy 0.4633 Gender-Accuracy 0.9396 Time taken for training: 14.863842725753784 secs\n",
      "Epoch 4 Batch 1100 Loss 0.7357 Age-Accuracy 0.4628 Gender-Accuracy 0.9395 Time taken for training: 14.859938383102417 secs\n",
      "Epoch 4 Batch 1200 Loss 0.7353 Age-Accuracy 0.4629 Gender-Accuracy 0.9396 Time taken for training: 14.844774961471558 secs\n",
      "Epoch 4 Batch 1300 Loss 0.7350 Age-Accuracy 0.4632 Gender-Accuracy 0.9396 Time taken for training: 14.850240230560303 secs\n",
      "Epoch 4 Batch 1400 Loss 0.7346 Age-Accuracy 0.4631 Gender-Accuracy 0.9396 Time taken for training: 14.854467391967773 secs\n",
      "Epoch 4 Batch 1500 Loss 0.7346 Age-Accuracy 0.4630 Gender-Accuracy 0.9397 Time taken for training: 14.989303588867188 secs\n",
      "Epoch 4 Batch 1600 Loss 0.7344 Age-Accuracy 0.4629 Gender-Accuracy 0.9397 Time taken for training: 14.863279581069946 secs\n",
      "Epoch 4 Batch 1700 Loss 0.7342 Age-Accuracy 0.4630 Gender-Accuracy 0.9397 Time taken for training: 14.86554479598999 secs\n",
      "Epoch 4 Batch 1800 Loss 0.7340 Age-Accuracy 0.4631 Gender-Accuracy 0.9398 Time taken for training: 14.855706453323364 secs\n",
      "Epoch 4 Batch 1900 Loss 0.7339 Age-Accuracy 0.4629 Gender-Accuracy 0.9399 Time taken for training: 14.958291053771973 secs\n",
      "Epoch 4 Batch 2000 Loss 0.7335 Age-Accuracy 0.4632 Gender-Accuracy 0.9399 Time taken for training: 14.916895151138306 secs\n",
      "Epoch 4 Batch 2100 Loss 0.7332 Age-Accuracy 0.4635 Gender-Accuracy 0.9400 Time taken for training: 14.875490665435791 secs\n",
      "Epoch 4 Batch 2200 Loss 0.7329 Age-Accuracy 0.4635 Gender-Accuracy 0.9401 Time taken for training: 14.848580360412598 secs\n",
      "Epoch 4 Batch 2300 Loss 0.7327 Age-Accuracy 0.4637 Gender-Accuracy 0.9402 Time taken for training: 14.868769407272339 secs\n",
      "Epoch 4 Batch 2400 Loss 0.7328 Age-Accuracy 0.4637 Gender-Accuracy 0.9401 Time taken for training: 14.878203868865967 secs\n",
      "Epoch 4 Batch 2500 Loss 0.7326 Age-Accuracy 0.4637 Gender-Accuracy 0.9401 Time taken for training: 14.846908569335938 secs\n",
      "Epoch 4 Batch 2600 Loss 0.7323 Age-Accuracy 0.4639 Gender-Accuracy 0.9401 Time taken for training: 14.855119466781616 secs\n",
      "Epoch 4 Batch 2700 Loss 0.7321 Age-Accuracy 0.4640 Gender-Accuracy 0.9402 Time taken for training: 14.848724842071533 secs\n",
      "Epoch 4 Batch 2800 Loss 0.7321 Age-Accuracy 0.4640 Gender-Accuracy 0.9402 Time taken for training: 14.849118947982788 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################## valid ################################################\n",
      "Epoch 4 Batch 2813 Loss 0.7503 Age-Accuracy 0.4554 Gender-Accuracy 0.9357           Time taken for validation: 56.58605337142944 secs\n",
      "Epoch 5 Batch 0 Loss 0.7339 Age-Accuracy 0.4648 Gender-Accuracy 0.9414 Time taken for training: 0.5725955963134766 secs\n",
      "Epoch 5 Batch 100 Loss 0.7243 Age-Accuracy 0.4679 Gender-Accuracy 0.9418 Time taken for training: 14.837981224060059 secs\n",
      "Epoch 5 Batch 200 Loss 0.7283 Age-Accuracy 0.4636 Gender-Accuracy 0.9412 Time taken for training: 14.817169427871704 secs\n",
      "Epoch 5 Batch 300 Loss 0.7271 Age-Accuracy 0.4643 Gender-Accuracy 0.9416 Time taken for training: 14.823451519012451 secs\n",
      "Epoch 5 Batch 400 Loss 0.7280 Age-Accuracy 0.4639 Gender-Accuracy 0.9411 Time taken for training: 14.840611934661865 secs\n",
      "Epoch 5 Batch 500 Loss 0.7269 Age-Accuracy 0.4646 Gender-Accuracy 0.9412 Time taken for training: 14.837584257125854 secs\n",
      "Epoch 5 Batch 600 Loss 0.7270 Age-Accuracy 0.4657 Gender-Accuracy 0.9408 Time taken for training: 14.84755277633667 secs\n",
      "Epoch 5 Batch 700 Loss 0.7279 Age-Accuracy 0.4656 Gender-Accuracy 0.9408 Time taken for training: 14.84648323059082 secs\n",
      "Epoch 5 Batch 800 Loss 0.7275 Age-Accuracy 0.4665 Gender-Accuracy 0.9407 Time taken for training: 14.843950986862183 secs\n",
      "Epoch 5 Batch 900 Loss 0.7271 Age-Accuracy 0.4668 Gender-Accuracy 0.9408 Time taken for training: 14.931743144989014 secs\n",
      "Epoch 5 Batch 1000 Loss 0.7269 Age-Accuracy 0.4671 Gender-Accuracy 0.9409 Time taken for training: 14.902507305145264 secs\n",
      "Epoch 5 Batch 1100 Loss 0.7271 Age-Accuracy 0.4667 Gender-Accuracy 0.9410 Time taken for training: 14.841753005981445 secs\n",
      "Epoch 5 Batch 1200 Loss 0.7267 Age-Accuracy 0.4670 Gender-Accuracy 0.9410 Time taken for training: 14.854288101196289 secs\n",
      "Epoch 5 Batch 1300 Loss 0.7264 Age-Accuracy 0.4674 Gender-Accuracy 0.9411 Time taken for training: 14.878262281417847 secs\n",
      "Epoch 5 Batch 1400 Loss 0.7260 Age-Accuracy 0.4675 Gender-Accuracy 0.9411 Time taken for training: 14.837952375411987 secs\n",
      "Epoch 5 Batch 1500 Loss 0.7260 Age-Accuracy 0.4673 Gender-Accuracy 0.9411 Time taken for training: 14.833051443099976 secs\n",
      "Epoch 5 Batch 1600 Loss 0.7259 Age-Accuracy 0.4672 Gender-Accuracy 0.9411 Time taken for training: 14.841984033584595 secs\n",
      "Epoch 5 Batch 1700 Loss 0.7257 Age-Accuracy 0.4674 Gender-Accuracy 0.9411 Time taken for training: 15.006573915481567 secs\n",
      "Epoch 5 Batch 1800 Loss 0.7255 Age-Accuracy 0.4675 Gender-Accuracy 0.9411 Time taken for training: 14.83901309967041 secs\n",
      "Epoch 5 Batch 1900 Loss 0.7255 Age-Accuracy 0.4675 Gender-Accuracy 0.9412 Time taken for training: 14.881863355636597 secs\n",
      "Epoch 5 Batch 2000 Loss 0.7252 Age-Accuracy 0.4678 Gender-Accuracy 0.9413 Time taken for training: 14.854676246643066 secs\n",
      "Epoch 5 Batch 2100 Loss 0.7249 Age-Accuracy 0.4681 Gender-Accuracy 0.9413 Time taken for training: 14.846496343612671 secs\n",
      "Epoch 5 Batch 2200 Loss 0.7246 Age-Accuracy 0.4680 Gender-Accuracy 0.9414 Time taken for training: 14.85699987411499 secs\n",
      "Epoch 5 Batch 2300 Loss 0.7244 Age-Accuracy 0.4681 Gender-Accuracy 0.9415 Time taken for training: 14.855242252349854 secs\n",
      "Epoch 5 Batch 2400 Loss 0.7245 Age-Accuracy 0.4681 Gender-Accuracy 0.9415 Time taken for training: 14.850204944610596 secs\n",
      "Epoch 5 Batch 2500 Loss 0.7243 Age-Accuracy 0.4682 Gender-Accuracy 0.9415 Time taken for training: 14.8983895778656 secs\n",
      "Epoch 5 Batch 2600 Loss 0.7240 Age-Accuracy 0.4684 Gender-Accuracy 0.9415 Time taken for training: 14.95217514038086 secs\n",
      "Epoch 5 Batch 2700 Loss 0.7238 Age-Accuracy 0.4685 Gender-Accuracy 0.9416 Time taken for training: 14.842808723449707 secs\n",
      "Epoch 5 Batch 2800 Loss 0.7238 Age-Accuracy 0.4686 Gender-Accuracy 0.9416 Time taken for training: 14.908046007156372 secs\n",
      "########################################## valid ################################################\n",
      "Epoch 5 Batch 2813 Loss 0.7473 Age-Accuracy 0.4569 Gender-Accuracy 0.9363           Time taken for validation: 55.99866271018982 secs\n",
      "Epoch 6 Batch 0 Loss 0.7210 Age-Accuracy 0.4648 Gender-Accuracy 0.9453 Time taken for training: 0.5274636745452881 secs\n",
      "Epoch 6 Batch 100 Loss 0.7165 Age-Accuracy 0.4721 Gender-Accuracy 0.9425 Time taken for training: 14.842402696609497 secs\n",
      "Epoch 6 Batch 200 Loss 0.7200 Age-Accuracy 0.4685 Gender-Accuracy 0.9423 Time taken for training: 14.81801462173462 secs\n",
      "Epoch 6 Batch 300 Loss 0.7187 Age-Accuracy 0.4701 Gender-Accuracy 0.9429 Time taken for training: 14.83625602722168 secs\n",
      "Epoch 6 Batch 400 Loss 0.7201 Age-Accuracy 0.4696 Gender-Accuracy 0.9423 Time taken for training: 14.830692768096924 secs\n",
      "Epoch 6 Batch 500 Loss 0.7191 Age-Accuracy 0.4702 Gender-Accuracy 0.9423 Time taken for training: 14.849149465560913 secs\n",
      "Epoch 6 Batch 600 Loss 0.7193 Age-Accuracy 0.4715 Gender-Accuracy 0.9420 Time taken for training: 14.86310625076294 secs\n",
      "Epoch 6 Batch 700 Loss 0.7202 Age-Accuracy 0.4713 Gender-Accuracy 0.9419 Time taken for training: 14.9470853805542 secs\n",
      "Epoch 6 Batch 800 Loss 0.7200 Age-Accuracy 0.4719 Gender-Accuracy 0.9418 Time taken for training: 14.863921642303467 secs\n",
      "Epoch 6 Batch 900 Loss 0.7197 Age-Accuracy 0.4721 Gender-Accuracy 0.9419 Time taken for training: 14.85431981086731 secs\n",
      "Epoch 6 Batch 1000 Loss 0.7194 Age-Accuracy 0.4723 Gender-Accuracy 0.9420 Time taken for training: 14.866955280303955 secs\n",
      "Epoch 6 Batch 1100 Loss 0.7196 Age-Accuracy 0.4719 Gender-Accuracy 0.9420 Time taken for training: 14.857023477554321 secs\n",
      "Epoch 6 Batch 1200 Loss 0.7192 Age-Accuracy 0.4719 Gender-Accuracy 0.9421 Time taken for training: 14.85972809791565 secs\n",
      "Epoch 6 Batch 1300 Loss 0.7189 Age-Accuracy 0.4721 Gender-Accuracy 0.9421 Time taken for training: 14.862322092056274 secs\n",
      "Epoch 6 Batch 1400 Loss 0.7185 Age-Accuracy 0.4721 Gender-Accuracy 0.9422 Time taken for training: 14.847651720046997 secs\n",
      "Epoch 6 Batch 1500 Loss 0.7186 Age-Accuracy 0.4719 Gender-Accuracy 0.9422 Time taken for training: 14.859572649002075 secs\n",
      "Epoch 6 Batch 1600 Loss 0.7185 Age-Accuracy 0.4718 Gender-Accuracy 0.9422 Time taken for training: 14.90224575996399 secs\n",
      "Epoch 6 Batch 1700 Loss 0.7184 Age-Accuracy 0.4718 Gender-Accuracy 0.9422 Time taken for training: 14.87217116355896 secs\n",
      "Epoch 6 Batch 1800 Loss 0.7182 Age-Accuracy 0.4720 Gender-Accuracy 0.9423 Time taken for training: 14.86284852027893 secs\n",
      "Epoch 6 Batch 1900 Loss 0.7183 Age-Accuracy 0.4718 Gender-Accuracy 0.9424 Time taken for training: 14.894644498825073 secs\n",
      "Epoch 6 Batch 2000 Loss 0.7180 Age-Accuracy 0.4720 Gender-Accuracy 0.9424 Time taken for training: 14.871236801147461 secs\n",
      "Epoch 6 Batch 2100 Loss 0.7177 Age-Accuracy 0.4723 Gender-Accuracy 0.9425 Time taken for training: 14.91055965423584 secs\n",
      "Epoch 6 Batch 2200 Loss 0.7174 Age-Accuracy 0.4722 Gender-Accuracy 0.9426 Time taken for training: 14.953343868255615 secs\n",
      "Epoch 6 Batch 2300 Loss 0.7173 Age-Accuracy 0.4723 Gender-Accuracy 0.9427 Time taken for training: 14.873976469039917 secs\n",
      "Epoch 6 Batch 2400 Loss 0.7173 Age-Accuracy 0.4724 Gender-Accuracy 0.9426 Time taken for training: 14.893661975860596 secs\n",
      "Epoch 6 Batch 2500 Loss 0.7172 Age-Accuracy 0.4723 Gender-Accuracy 0.9427 Time taken for training: 14.880016088485718 secs\n",
      "Epoch 6 Batch 2600 Loss 0.7170 Age-Accuracy 0.4725 Gender-Accuracy 0.9427 Time taken for training: 14.92274260520935 secs\n",
      "Epoch 6 Batch 2700 Loss 0.7168 Age-Accuracy 0.4726 Gender-Accuracy 0.9427 Time taken for training: 14.867675065994263 secs\n",
      "Epoch 6 Batch 2800 Loss 0.7169 Age-Accuracy 0.4726 Gender-Accuracy 0.9427 Time taken for training: 14.879245042800903 secs\n",
      "########################################## valid ################################################\n",
      "Epoch 6 Batch 2813 Loss 0.7452 Age-Accuracy 0.4581 Gender-Accuracy 0.9367           Time taken for validation: 57.303165912628174 secs\n",
      "Epoch 7 Batch 0 Loss 0.7192 Age-Accuracy 0.4688 Gender-Accuracy 0.9492 Time taken for training: 0.5525190830230713 secs\n",
      "Epoch 7 Batch 100 Loss 0.7099 Age-Accuracy 0.4751 Gender-Accuracy 0.9438 Time taken for training: 14.830856084823608 secs\n",
      "Epoch 7 Batch 200 Loss 0.7137 Age-Accuracy 0.4725 Gender-Accuracy 0.9437 Time taken for training: 14.85023045539856 secs\n",
      "Epoch 7 Batch 300 Loss 0.7123 Age-Accuracy 0.4733 Gender-Accuracy 0.9442 Time taken for training: 14.847186803817749 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 400 Loss 0.7137 Age-Accuracy 0.4729 Gender-Accuracy 0.9435 Time taken for training: 14.844737529754639 secs\n",
      "Epoch 7 Batch 500 Loss 0.7131 Age-Accuracy 0.4731 Gender-Accuracy 0.9436 Time taken for training: 14.877125978469849 secs\n",
      "Epoch 7 Batch 600 Loss 0.7133 Age-Accuracy 0.4740 Gender-Accuracy 0.9432 Time taken for training: 14.867357969284058 secs\n",
      "Epoch 7 Batch 700 Loss 0.7142 Age-Accuracy 0.4741 Gender-Accuracy 0.9432 Time taken for training: 14.859890699386597 secs\n",
      "Epoch 7 Batch 800 Loss 0.7140 Age-Accuracy 0.4751 Gender-Accuracy 0.9429 Time taken for training: 14.866142988204956 secs\n",
      "Epoch 7 Batch 900 Loss 0.7136 Age-Accuracy 0.4753 Gender-Accuracy 0.9431 Time taken for training: 15.034072160720825 secs\n",
      "Epoch 7 Batch 1000 Loss 0.7133 Age-Accuracy 0.4755 Gender-Accuracy 0.9433 Time taken for training: 14.86722731590271 secs\n",
      "Epoch 7 Batch 1100 Loss 0.7135 Age-Accuracy 0.4752 Gender-Accuracy 0.9433 Time taken for training: 14.870012044906616 secs\n",
      "Epoch 7 Batch 1200 Loss 0.7132 Age-Accuracy 0.4752 Gender-Accuracy 0.9434 Time taken for training: 14.894350290298462 secs\n",
      "Epoch 7 Batch 1300 Loss 0.7131 Age-Accuracy 0.4752 Gender-Accuracy 0.9434 Time taken for training: 14.868470907211304 secs\n",
      "Epoch 7 Batch 1400 Loss 0.7126 Age-Accuracy 0.4752 Gender-Accuracy 0.9435 Time taken for training: 14.893987655639648 secs\n",
      "Epoch 7 Batch 1500 Loss 0.7127 Age-Accuracy 0.4751 Gender-Accuracy 0.9435 Time taken for training: 14.86830997467041 secs\n",
      "Epoch 7 Batch 1600 Loss 0.7127 Age-Accuracy 0.4749 Gender-Accuracy 0.9435 Time taken for training: 14.871045351028442 secs\n",
      "Epoch 7 Batch 1700 Loss 0.7126 Age-Accuracy 0.4750 Gender-Accuracy 0.9434 Time taken for training: 14.988132238388062 secs\n",
      "Epoch 7 Batch 1800 Loss 0.7125 Age-Accuracy 0.4752 Gender-Accuracy 0.9434 Time taken for training: 14.864205121994019 secs\n",
      "Epoch 7 Batch 1900 Loss 0.7125 Age-Accuracy 0.4751 Gender-Accuracy 0.9436 Time taken for training: 14.883715629577637 secs\n",
      "Epoch 7 Batch 2000 Loss 0.7123 Age-Accuracy 0.4753 Gender-Accuracy 0.9436 Time taken for training: 14.9556245803833 secs\n",
      "Epoch 7 Batch 2100 Loss 0.7120 Age-Accuracy 0.4756 Gender-Accuracy 0.9437 Time taken for training: 14.926132202148438 secs\n",
      "Epoch 7 Batch 2200 Loss 0.7118 Age-Accuracy 0.4756 Gender-Accuracy 0.9438 Time taken for training: 14.908262014389038 secs\n",
      "Epoch 7 Batch 2300 Loss 0.7117 Age-Accuracy 0.4758 Gender-Accuracy 0.9438 Time taken for training: 14.878753423690796 secs\n",
      "Epoch 7 Batch 2400 Loss 0.7117 Age-Accuracy 0.4758 Gender-Accuracy 0.9438 Time taken for training: 14.89039921760559 secs\n",
      "Epoch 7 Batch 2500 Loss 0.7117 Age-Accuracy 0.4756 Gender-Accuracy 0.9438 Time taken for training: 14.901125431060791 secs\n",
      "Epoch 7 Batch 2600 Loss 0.7114 Age-Accuracy 0.4758 Gender-Accuracy 0.9438 Time taken for training: 15.013259887695312 secs\n",
      "Epoch 7 Batch 2700 Loss 0.7113 Age-Accuracy 0.4758 Gender-Accuracy 0.9439 Time taken for training: 14.868218183517456 secs\n",
      "Epoch 7 Batch 2800 Loss 0.7114 Age-Accuracy 0.4759 Gender-Accuracy 0.9439 Time taken for training: 14.8883376121521 secs\n",
      "########################################## valid ################################################\n",
      "Epoch 7 Batch 2813 Loss 0.7437 Age-Accuracy 0.4591 Gender-Accuracy 0.9370           Time taken for validation: 57.867310762405396 secs\n",
      "Epoch 8 Batch 0 Loss 0.7174 Age-Accuracy 0.4492 Gender-Accuracy 0.9453 Time taken for training: 0.603569746017456 secs\n",
      "Epoch 8 Batch 100 Loss 0.7052 Age-Accuracy 0.4770 Gender-Accuracy 0.9452 Time taken for training: 14.866044998168945 secs\n",
      "Epoch 8 Batch 200 Loss 0.7086 Age-Accuracy 0.4755 Gender-Accuracy 0.9446 Time taken for training: 14.859970092773438 secs\n",
      "Epoch 8 Batch 300 Loss 0.7072 Age-Accuracy 0.4762 Gender-Accuracy 0.9454 Time taken for training: 14.864124298095703 secs\n",
      "Epoch 8 Batch 400 Loss 0.7086 Age-Accuracy 0.4758 Gender-Accuracy 0.9446 Time taken for training: 14.863696336746216 secs\n",
      "Epoch 8 Batch 500 Loss 0.7080 Age-Accuracy 0.4762 Gender-Accuracy 0.9445 Time taken for training: 14.98354697227478 secs\n",
      "Epoch 8 Batch 600 Loss 0.7084 Age-Accuracy 0.4772 Gender-Accuracy 0.9440 Time taken for training: 14.987090587615967 secs\n",
      "Epoch 8 Batch 700 Loss 0.7093 Age-Accuracy 0.4769 Gender-Accuracy 0.9441 Time taken for training: 14.989911794662476 secs\n",
      "Epoch 8 Batch 800 Loss 0.7090 Age-Accuracy 0.4777 Gender-Accuracy 0.9439 Time taken for training: 14.879739999771118 secs\n",
      "Epoch 8 Batch 900 Loss 0.7087 Age-Accuracy 0.4778 Gender-Accuracy 0.9441 Time taken for training: 14.862180948257446 secs\n",
      "Epoch 8 Batch 1000 Loss 0.7084 Age-Accuracy 0.4782 Gender-Accuracy 0.9443 Time taken for training: 14.882749557495117 secs\n",
      "Epoch 8 Batch 1100 Loss 0.7085 Age-Accuracy 0.4780 Gender-Accuracy 0.9443 Time taken for training: 14.860853910446167 secs\n",
      "Epoch 8 Batch 1200 Loss 0.7083 Age-Accuracy 0.4780 Gender-Accuracy 0.9443 Time taken for training: 14.870227336883545 secs\n",
      "Epoch 8 Batch 1300 Loss 0.7081 Age-Accuracy 0.4783 Gender-Accuracy 0.9443 Time taken for training: 14.865958213806152 secs\n",
      "Epoch 8 Batch 1400 Loss 0.7077 Age-Accuracy 0.4784 Gender-Accuracy 0.9444 Time taken for training: 14.86024808883667 secs\n",
      "Epoch 8 Batch 1500 Loss 0.7077 Age-Accuracy 0.4785 Gender-Accuracy 0.9444 Time taken for training: 15.103203535079956 secs\n",
      "Epoch 8 Batch 1600 Loss 0.7077 Age-Accuracy 0.4782 Gender-Accuracy 0.9443 Time taken for training: 14.974746465682983 secs\n",
      "Epoch 8 Batch 1700 Loss 0.7076 Age-Accuracy 0.4783 Gender-Accuracy 0.9443 Time taken for training: 14.847819328308105 secs\n",
      "Epoch 8 Batch 1800 Loss 0.7075 Age-Accuracy 0.4784 Gender-Accuracy 0.9443 Time taken for training: 14.856321334838867 secs\n",
      "Epoch 8 Batch 1900 Loss 0.7075 Age-Accuracy 0.4782 Gender-Accuracy 0.9444 Time taken for training: 14.867013692855835 secs\n",
      "Epoch 8 Batch 2000 Loss 0.7073 Age-Accuracy 0.4784 Gender-Accuracy 0.9444 Time taken for training: 14.844050168991089 secs\n",
      "Epoch 8 Batch 2100 Loss 0.7071 Age-Accuracy 0.4787 Gender-Accuracy 0.9445 Time taken for training: 14.84926462173462 secs\n",
      "Epoch 8 Batch 2200 Loss 0.7068 Age-Accuracy 0.4787 Gender-Accuracy 0.9446 Time taken for training: 14.852832317352295 secs\n",
      "Epoch 8 Batch 2300 Loss 0.7068 Age-Accuracy 0.4788 Gender-Accuracy 0.9446 Time taken for training: 14.843016147613525 secs\n",
      "Epoch 8 Batch 2400 Loss 0.7069 Age-Accuracy 0.4788 Gender-Accuracy 0.9446 Time taken for training: 14.86360216140747 secs\n",
      "Epoch 8 Batch 2500 Loss 0.7067 Age-Accuracy 0.4787 Gender-Accuracy 0.9446 Time taken for training: 14.849361658096313 secs\n",
      "Epoch 8 Batch 2600 Loss 0.7065 Age-Accuracy 0.4790 Gender-Accuracy 0.9446 Time taken for training: 14.849843740463257 secs\n",
      "Epoch 8 Batch 2700 Loss 0.7064 Age-Accuracy 0.4790 Gender-Accuracy 0.9447 Time taken for training: 14.847018480300903 secs\n",
      "Epoch 8 Batch 2800 Loss 0.7065 Age-Accuracy 0.4790 Gender-Accuracy 0.9447 Time taken for training: 14.847707986831665 secs\n",
      "########################################## valid ################################################\n",
      "Epoch 8 Batch 2813 Loss 0.7427 Age-Accuracy 0.4598 Gender-Accuracy 0.9372           Time taken for validation: 56.57116985321045 secs\n",
      "Epoch 9 Batch 0 Loss 0.7174 Age-Accuracy 0.4258 Gender-Accuracy 0.9453 Time taken for training: 0.48696231842041016 secs\n",
      "Epoch 9 Batch 100 Loss 0.7011 Age-Accuracy 0.4810 Gender-Accuracy 0.9447 Time taken for training: 14.82816219329834 secs\n",
      "Epoch 9 Batch 200 Loss 0.7050 Age-Accuracy 0.4776 Gender-Accuracy 0.9446 Time taken for training: 14.819747924804688 secs\n",
      "Epoch 9 Batch 300 Loss 0.7031 Age-Accuracy 0.4794 Gender-Accuracy 0.9454 Time taken for training: 14.846360921859741 secs\n",
      "Epoch 9 Batch 400 Loss 0.7046 Age-Accuracy 0.4785 Gender-Accuracy 0.9447 Time taken for training: 14.921541452407837 secs\n",
      "Epoch 9 Batch 500 Loss 0.7039 Age-Accuracy 0.4789 Gender-Accuracy 0.9446 Time taken for training: 14.863439083099365 secs\n",
      "Epoch 9 Batch 600 Loss 0.7041 Age-Accuracy 0.4794 Gender-Accuracy 0.9443 Time taken for training: 14.84094762802124 secs\n",
      "Epoch 9 Batch 700 Loss 0.7050 Age-Accuracy 0.4790 Gender-Accuracy 0.9444 Time taken for training: 14.848599672317505 secs\n",
      "Epoch 9 Batch 800 Loss 0.7046 Age-Accuracy 0.4799 Gender-Accuracy 0.9442 Time taken for training: 14.851308107376099 secs\n",
      "Epoch 9 Batch 900 Loss 0.7043 Age-Accuracy 0.4798 Gender-Accuracy 0.9443 Time taken for training: 14.87488055229187 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 1000 Loss 0.7040 Age-Accuracy 0.4802 Gender-Accuracy 0.9445 Time taken for training: 14.853564977645874 secs\n",
      "Epoch 9 Batch 1100 Loss 0.7042 Age-Accuracy 0.4800 Gender-Accuracy 0.9446 Time taken for training: 14.849393606185913 secs\n",
      "Epoch 9 Batch 1200 Loss 0.7039 Age-Accuracy 0.4801 Gender-Accuracy 0.9447 Time taken for training: 14.848146915435791 secs\n",
      "Epoch 9 Batch 1300 Loss 0.7037 Age-Accuracy 0.4802 Gender-Accuracy 0.9448 Time taken for training: 14.869696140289307 secs\n",
      "Epoch 9 Batch 1400 Loss 0.7033 Age-Accuracy 0.4804 Gender-Accuracy 0.9449 Time taken for training: 14.85472297668457 secs\n",
      "Epoch 9 Batch 1500 Loss 0.7033 Age-Accuracy 0.4804 Gender-Accuracy 0.9449 Time taken for training: 14.847445964813232 secs\n",
      "Epoch 9 Batch 1600 Loss 0.7032 Age-Accuracy 0.4803 Gender-Accuracy 0.9449 Time taken for training: 14.86722707748413 secs\n",
      "Epoch 9 Batch 1700 Loss 0.7032 Age-Accuracy 0.4803 Gender-Accuracy 0.9449 Time taken for training: 14.868518829345703 secs\n",
      "Epoch 9 Batch 1800 Loss 0.7031 Age-Accuracy 0.4804 Gender-Accuracy 0.9450 Time taken for training: 15.010791063308716 secs\n",
      "Epoch 9 Batch 1900 Loss 0.7032 Age-Accuracy 0.4803 Gender-Accuracy 0.9451 Time taken for training: 14.873054504394531 secs\n",
      "Epoch 9 Batch 2000 Loss 0.7029 Age-Accuracy 0.4806 Gender-Accuracy 0.9451 Time taken for training: 14.857994079589844 secs\n",
      "Epoch 9 Batch 2100 Loss 0.7027 Age-Accuracy 0.4810 Gender-Accuracy 0.9451 Time taken for training: 14.881490230560303 secs\n",
      "Epoch 9 Batch 2200 Loss 0.7025 Age-Accuracy 0.4810 Gender-Accuracy 0.9452 Time taken for training: 14.857758522033691 secs\n",
      "Epoch 9 Batch 2300 Loss 0.7024 Age-Accuracy 0.4811 Gender-Accuracy 0.9452 Time taken for training: 14.899134159088135 secs\n",
      "Epoch 9 Batch 2400 Loss 0.7025 Age-Accuracy 0.4810 Gender-Accuracy 0.9452 Time taken for training: 14.871986389160156 secs\n",
      "Epoch 9 Batch 2500 Loss 0.7024 Age-Accuracy 0.4810 Gender-Accuracy 0.9452 Time taken for training: 14.86051321029663 secs\n",
      "Epoch 9 Batch 2600 Loss 0.7022 Age-Accuracy 0.4813 Gender-Accuracy 0.9452 Time taken for training: 14.874528884887695 secs\n",
      "Epoch 9 Batch 2700 Loss 0.7021 Age-Accuracy 0.4813 Gender-Accuracy 0.9453 Time taken for training: 14.877234935760498 secs\n",
      "Epoch 9 Batch 2800 Loss 0.7022 Age-Accuracy 0.4813 Gender-Accuracy 0.9453 Time taken for training: 14.903659582138062 secs\n",
      "########################################## valid ################################################\n",
      "Epoch 9 Batch 2813 Loss 0.7419 Age-Accuracy 0.4603 Gender-Accuracy 0.9374           Time taken for validation: 55.99681234359741 secs\n",
      "Epoch 10 Batch 0 Loss 0.7110 Age-Accuracy 0.4492 Gender-Accuracy 0.9492 Time taken for training: 0.5875682830810547 secs\n",
      "Epoch 10 Batch 100 Loss 0.6963 Age-Accuracy 0.4843 Gender-Accuracy 0.9464 Time taken for training: 14.830811738967896 secs\n",
      "Epoch 10 Batch 200 Loss 0.6999 Age-Accuracy 0.4813 Gender-Accuracy 0.9459 Time taken for training: 14.844996690750122 secs\n",
      "Epoch 10 Batch 300 Loss 0.6989 Age-Accuracy 0.4831 Gender-Accuracy 0.9467 Time taken for training: 14.855472326278687 secs\n",
      "Epoch 10 Batch 400 Loss 0.7004 Age-Accuracy 0.4817 Gender-Accuracy 0.9457 Time taken for training: 14.87204098701477 secs\n",
      "Epoch 10 Batch 500 Loss 0.6998 Age-Accuracy 0.4820 Gender-Accuracy 0.9456 Time taken for training: 14.88973617553711 secs\n",
      "Epoch 10 Batch 600 Loss 0.7002 Age-Accuracy 0.4825 Gender-Accuracy 0.9453 Time taken for training: 14.881314754486084 secs\n",
      "Epoch 10 Batch 700 Loss 0.7011 Age-Accuracy 0.4820 Gender-Accuracy 0.9452 Time taken for training: 14.891645431518555 secs\n",
      "Epoch 10 Batch 800 Loss 0.7006 Age-Accuracy 0.4828 Gender-Accuracy 0.9452 Time taken for training: 14.874132633209229 secs\n",
      "Epoch 10 Batch 900 Loss 0.7003 Age-Accuracy 0.4832 Gender-Accuracy 0.9454 Time taken for training: 14.8887779712677 secs\n",
      "Epoch 10 Batch 1000 Loss 0.6999 Age-Accuracy 0.4835 Gender-Accuracy 0.9456 Time taken for training: 14.8833327293396 secs\n",
      "Epoch 10 Batch 1100 Loss 0.7001 Age-Accuracy 0.4832 Gender-Accuracy 0.9456 Time taken for training: 14.885761976242065 secs\n",
      "Epoch 10 Batch 1200 Loss 0.6997 Age-Accuracy 0.4836 Gender-Accuracy 0.9456 Time taken for training: 14.949943780899048 secs\n",
      "Epoch 10 Batch 1300 Loss 0.6995 Age-Accuracy 0.4837 Gender-Accuracy 0.9457 Time taken for training: 14.93781590461731 secs\n",
      "Epoch 10 Batch 1400 Loss 0.6992 Age-Accuracy 0.4837 Gender-Accuracy 0.9458 Time taken for training: 14.91101861000061 secs\n",
      "Epoch 10 Batch 1500 Loss 0.6993 Age-Accuracy 0.4834 Gender-Accuracy 0.9458 Time taken for training: 14.872265100479126 secs\n",
      "Epoch 10 Batch 1600 Loss 0.6992 Age-Accuracy 0.4833 Gender-Accuracy 0.9458 Time taken for training: 14.963702917098999 secs\n",
      "Epoch 10 Batch 1700 Loss 0.6991 Age-Accuracy 0.4835 Gender-Accuracy 0.9458 Time taken for training: 14.888663291931152 secs\n",
      "Epoch 10 Batch 1800 Loss 0.6990 Age-Accuracy 0.4835 Gender-Accuracy 0.9459 Time taken for training: 14.87467074394226 secs\n",
      "Epoch 10 Batch 1900 Loss 0.6991 Age-Accuracy 0.4834 Gender-Accuracy 0.9459 Time taken for training: 14.99088740348816 secs\n",
      "Epoch 10 Batch 2000 Loss 0.6988 Age-Accuracy 0.4836 Gender-Accuracy 0.9459 Time taken for training: 14.892072200775146 secs\n",
      "Epoch 10 Batch 2100 Loss 0.6987 Age-Accuracy 0.4839 Gender-Accuracy 0.9459 Time taken for training: 14.892690420150757 secs\n",
      "Epoch 10 Batch 2200 Loss 0.6984 Age-Accuracy 0.4839 Gender-Accuracy 0.9460 Time taken for training: 14.872052907943726 secs\n",
      "Epoch 10 Batch 2300 Loss 0.6984 Age-Accuracy 0.4840 Gender-Accuracy 0.9460 Time taken for training: 14.941700220108032 secs\n",
      "Epoch 10 Batch 2400 Loss 0.6986 Age-Accuracy 0.4840 Gender-Accuracy 0.9459 Time taken for training: 14.903520822525024 secs\n",
      "Epoch 10 Batch 2500 Loss 0.6984 Age-Accuracy 0.4839 Gender-Accuracy 0.9460 Time taken for training: 14.958951711654663 secs\n",
      "Epoch 10 Batch 2600 Loss 0.6982 Age-Accuracy 0.4840 Gender-Accuracy 0.9460 Time taken for training: 14.910478830337524 secs\n",
      "Epoch 10 Batch 2700 Loss 0.6981 Age-Accuracy 0.4841 Gender-Accuracy 0.9461 Time taken for training: 14.87337350845337 secs\n",
      "Epoch 10 Batch 2800 Loss 0.6982 Age-Accuracy 0.4842 Gender-Accuracy 0.9460 Time taken for training: 14.887127161026001 secs\n",
      "########################################## valid ################################################\n",
      "Epoch 10 Batch 2813 Loss 0.7416 Age-Accuracy 0.4607 Gender-Accuracy 0.9376           Time taken for validation: 57.34906196594238 secs\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    age_train_accuracy.reset_states()\n",
    "    gender_train_accuracy.reset_states()\n",
    "\n",
    "    '''\n",
    "    inp0: stat feat;\n",
    "    inp1: ad_id list;\n",
    "    inp2: product_id list;\n",
    "    inp3: advertiser_id list;\n",
    "    inp4: click_times list;\n",
    "    '''\n",
    "    for (batch, (inp0, inp1, inp2, inp3, inp4, tar)) in enumerate(tr_ds):\n",
    "        train_step((inp0, inp1, inp2, inp3, inp4), tar)\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Age-Accuracy {:.4f} Gender-Accuracy {:.4f} Time taken for training: {} secs'\n",
    "                   .format(epoch + 1, batch, train_loss.result(), \n",
    "                           age_train_accuracy.result(), gender_train_accuracy.result(),\n",
    "                          time.time()-start))\n",
    "            start = time.time()\n",
    "            \n",
    "    tmp = time.time()\n",
    "    for inp0, inp1, inp2, inp3, inp4, tar in vl_ds:\n",
    "        valid_step((inp0, inp1, inp2, inp3, inp4), tar)    \n",
    "    print('########################################## valid ################################################')\n",
    "    print('Epoch {} Batch {} Loss {:.4f} Age-Accuracy {:.4f} Gender-Accuracy {:.4f} \\\n",
    "          Time taken for validation: {} secs'\n",
    "          .format(epoch + 1, batch, \n",
    "                  valid_loss.result(), age_valid_accuracy.result(), gender_valid_accuracy.result(),\n",
    "                  time.time() - tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
