{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# set device GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tf.test.is_gpu_available()\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from config import *\n",
    "\n",
    "from tools import *\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_NAME = ['ad_id', 'product_id', 'advertiser_id']\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_user_log = pd.read_pickle(TRAIN_DIR+USER_LOG_PATH)\n",
    "# ts_user_log = pd.read_pickle(TEST_DIR+USER_LOG_PATH)\n",
    "\n",
    "# tr_ad_id_log = pd.read_pickle(TRAIN_DIR+AD_INFO_PATH)\n",
    "# ts_ad_id_log = pd.read_pickle(TEST_DIR+AD_INFO_PATH)\n",
    "\n",
    "# tr_df = pd.concat([tr_user_log, tr_ad_id_log], axis=1)\n",
    "# ts_df = pd.concat([ts_user_log, ts_ad_id_log], axis=1)\n",
    "\n",
    "# tr_df = tr_df[['user_id', 'age', 'gender', 'ad_id', 'product_id', 'advertiser_id', 'click_times']]\n",
    "# ts_df = ts_df[['user_id', 'ad_id', 'product_id', 'advertiser_id', 'click_times']]\n",
    "\n",
    "# tr_df['age'] = tr_df['age'] - 1\n",
    "# tr_df['gender'] = tr_df['gender'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入gensim预训练词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sizes = []\n",
    "wv_matrixes = []\n",
    "for col in COLS_NAME:\n",
    "    #load w2v matrix\n",
    "    f = open(TRAIN_DIR+'gensim_%s_dict.js'%col,'r')\n",
    "    a = f.read()\n",
    "    vocab_dict = eval(a)\n",
    "    f.close()\n",
    "    filter_keys = set(vocab_dict.keys())\n",
    "    vocab_size = len(filter_keys) + 1\n",
    "\n",
    "    wv_matrix = np.load(TRAIN_DIR+'gensim_%s.npy'%col)\n",
    "    row = np.random.uniform(size=(1, wv_matrix.shape[1]))\n",
    "\n",
    "    wv_matrix = np.concatenate([row, wv_matrix], axis=0)\n",
    "\n",
    "#     ### process and get click list\n",
    "#     tr_df[col] = tr_df[col].astype(str)\n",
    "#     ts_df[col] = ts_df[col].astype(str)\n",
    "\n",
    "#     tr_df = tr_df[tr_df[col].isin(filter_keys)]\n",
    "#     ts_df = ts_df[ts_df[col].isin(filter_keys)]\n",
    "\n",
    "#     tr_df[col] = tr_df[col].map(lambda x: vocab_dict[x]) + 1\n",
    "#     ts_df[col] = ts_df[col].map(lambda x: vocab_dict[x]) + 1\n",
    "    \n",
    "    vocab_sizes.append(vocab_size)\n",
    "    wv_matrixes.append(wv_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取点击列表和对应的广告信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_clk_list(df):\n",
    "#     return list(df.values)\n",
    "\n",
    "# tr_df = tr_df.groupby(['user_id']).agg({'age': 'first', \n",
    "#                                         'gender': 'first', \n",
    "#                                         'click_times': lambda x: get_clk_list(x), \n",
    "#                                         'ad_id': lambda x: get_clk_list(x),\n",
    "#                                         'product_id': lambda x: get_clk_list(x),\n",
    "#                                         'advertiser_id': lambda x: get_clk_list(x)}).reset_index()\n",
    "\n",
    "# ts_df = ts_df.groupby(['user_id']).agg({'click_times': lambda x: get_clk_list(x), \n",
    "#                                         'ad_id': lambda x: get_clk_list(x),\n",
    "#                                         'product_id': lambda x: get_clk_list(x),\n",
    "#                                         'advertiser_id': lambda x: get_clk_list(x)}).reset_index()\n",
    "\n",
    "# tr_df.to_pickle('/home/baode/huangzc/tencent/data/train_preliminary/3shuru.pkl')\n",
    "\n",
    "# ts_df.to_pickle('/home/baode/huangzc/tencent/data/test/3shuru.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df = pd.read_pickle('/home/baode/huangzc/tencent/data/train_preliminary/3shuru.pkl')\n",
    "ts_df = pd.read_pickle('/home/baode/huangzc/tencent/data/test/3shuru.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切分 train 和 test 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(tr_df)) <= 0.8\n",
    "vl_df = tr_df[~msk]\n",
    "tr_df = tr_df[msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 4\n",
    "n2 = 3\n",
    "\n",
    "d_model = 128\n",
    "dff = 256\n",
    "num_heads = 4\n",
    "\n",
    "dropout_rate = 0.1\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding 和mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len:  153\n"
     ]
    }
   ],
   "source": [
    "### cut lenght and pad sequence\n",
    "sentence_size = int(min(tr_df['ad_id'].map(lambda x: len(x)).quantile(0.99), ts_df['ad_id'].map(lambda x: len(x)).quantile(0.99)))\n",
    "print('max len: ', sentence_size)\n",
    "\n",
    "### pad or trunc\n",
    "def pad_or_trunc(t):\n",
    "    dim = tf.size(t)\n",
    "    return tf.cond(tf.equal(dim, sentence_size), lambda: t,\n",
    "                    lambda: tf.cond(tf.greater(dim, sentence_size), lambda: tf.slice(t, [0], [sentence_size]), \n",
    "                                     lambda: tf.concat([t, tf.zeros(dtype=tf.int64, shape=sentence_size-dim)], 0)))\n",
    "\n",
    "### padding mask\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # 添加额外的维度来将填充加到\n",
    "    # 注意力对数（logits）。\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "### pool mask\n",
    "def create_pooling_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # 添加额外的维度来将填充加到\n",
    "    # 注意力对数（logits）。\n",
    "    return seq[:, :, tf.newaxis]  # (batch_size, seq_len, 1)\n",
    "\n",
    "# # ## train pad_or_truc\n",
    "# vals = tf.constant([[1, 1, 1], [2, 2, 2], [3, 3, 3]], dtype=tf.int64)\n",
    "# dset1 = tf.data.Dataset.from_tensor_slices(vals)\n",
    "# y1 = tf.data.Dataset.from_tensor_slices(tf.constant([1, 1, 1], dtype=tf.int64))\n",
    "# y2 = tf.data.Dataset.from_tensor_slices(tf.constant([1, 1, 1], dtype=tf.int64))\n",
    "# y = tf.data.Dataset.zip((y1, y2))\n",
    "# dset1 = tf.data.Dataset.zip((dset1, y))\n",
    "# dset2 = dset1.map(lambda x, pair: (pad_or_trunc(x), pair))\n",
    "\n",
    "# for li in dset2.take(1):\n",
    "#     print(li)\n",
    "\n",
    "# # ## test pad_or_truc\n",
    "# vals = tf.constant([[1, 1, 1], [2, 2, 2], [3, 3, 3]], dtype=tf.int64)\n",
    "# dset1 = tf.data.Dataset.from_tensor_slices(vals)\n",
    "# dset2 = dset1.map(pad_or_trunc)\n",
    "\n",
    "# for li in dset2.take(1):\n",
    "#     print(li)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "### make train dataset\n",
    "def gen():\n",
    "    for row in tr_df.itertuples():\n",
    "        ad_id_li, product_id_li, advertiser_id_li, clk_li, age, gender = getattr(row, COLS_NAME[0]),\\\n",
    "                                                                         getattr(row, COLS_NAME[1]),\\\n",
    "                                                                         getattr(row, COLS_NAME[2]),\\\n",
    "                                                                         getattr(row, 'click_times'), \\\n",
    "                                                                         getattr(row, 'age'), \\\n",
    "                                                                         getattr(row, 'gender')\n",
    "\n",
    "        yield (ad_id_li, product_id_li, advertiser_id_li, clk_li, (age, gender))\n",
    "\n",
    "tr_ds = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     (tf.int64, tf.int64, tf.int64, tf.int64, (tf.int64, tf.int64)), \n",
    "     (tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), (tf.TensorShape([]), tf.TensorShape([]))))\n",
    "\n",
    "### make valid dataset\n",
    "def gen():\n",
    "    for row in vl_df.itertuples():\n",
    "        ad_id_li, product_id_li, advertiser_id_li, clk_li, age, gender = getattr(row, COLS_NAME[0]),\\\n",
    "                                                                         getattr(row, COLS_NAME[1]),\\\n",
    "                                                                         getattr(row, COLS_NAME[2]),\\\n",
    "                                                                         getattr(row, 'click_times'), \\\n",
    "                                                                         getattr(row, 'age'), \\\n",
    "                                                                         getattr(row, 'gender')\n",
    "\n",
    "        yield (ad_id_li, product_id_li, advertiser_id_li, clk_li, (age, gender))\n",
    "\n",
    "vl_ds = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     (tf.int64, tf.int64, tf.int64, tf.int64, (tf.int64, tf.int64)), \n",
    "     (tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), (tf.TensorShape([]), tf.TensorShape([]))))\n",
    "\n",
    "### make test dataset\n",
    "def gen():\n",
    "    for row in ts_df.itertuples():\n",
    "        ad_id_li, product_id_li, advertiser_id_li, clk_li = getattr(row, COLS_NAME[0]),\\\n",
    "                                                             getattr(row, COLS_NAME[1]),\\\n",
    "                                                             getattr(row, COLS_NAME[2]),\\\n",
    "                                                             getattr(row, 'click_times')\n",
    "        yield (ad_id_li, product_id_li, advertiser_id_li, clk_li)\n",
    "\n",
    "ts_ds = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     (tf.int64, tf.int64, tf.int64, tf.int64), \n",
    "     (tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([None])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op CacheDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ShuffleDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op BatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "tr_ds = tr_ds.map(lambda ad, product, advertiser, clk_times, pair: (pad_or_trunc(ad), \n",
    "                                                                     pad_or_trunc(product), \n",
    "                                                                     pad_or_trunc(advertiser), \n",
    "                                                                     pad_or_trunc(clk_times), \n",
    "                                                                     pair), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "tr_ds = tr_ds.cache()\n",
    "tr_ds = tr_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "tr_ds = tr_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "vl_ds = vl_ds.map(lambda ad, product, advertiser, clk_times, pair: (pad_or_trunc(ad), \n",
    "                                                                     pad_or_trunc(product), \n",
    "                                                                     pad_or_trunc(advertiser), \n",
    "                                                                     pad_or_trunc(clk_times), \n",
    "                                                                     pair), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "vl_ds = vl_ds.cache()\n",
    "vl_ds = vl_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "vl_ds = vl_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ts_ds = ts_ds.map(lambda ad, product, advertiser, clk_times: (pad_or_trunc(ad), \n",
    "                                                               pad_or_trunc(product), \n",
    "                                                               pad_or_trunc(advertiser), \n",
    "                                                               pad_or_trunc(clk_times)), num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化器和学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# with tf.device('/gpu:6'):\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'transformer' from '/home/baode/huangzc/tencent/code/tencent_competition/Transformer/transformer.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformer\n",
    "import imp\n",
    "imp.reload(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransLSTM(tf.keras.layers.Layer):\n",
    "    def __init__(self, n1, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, weights,\n",
    "                  n2, lstm_dims,\n",
    "                  pool_size, pool_strides,\n",
    "                  rate):\n",
    "        super(TransLSTM, self).__init__()\n",
    "            \n",
    "        self.n2 = n2        \n",
    "        self.transformer_enc = Encoder(num_layers=n1, \n",
    "                                       d_model=d_model, \n",
    "                                       num_heads=num_heads, \n",
    "                                       dff=dff, \n",
    "                                       input_vocab_size=input_vocab_size,\n",
    "                                       maximum_position_encoding=maximum_position_encoding, \n",
    "                                       rate=rate, \n",
    "                                       weights=weights)\n",
    "        \n",
    "        self.lstm = [tf.keras.layers.LSTM(lstm_dims, return_sequences=True) for _ in range(n2)]\n",
    "        self.max_pool = tf.keras.layers.MaxPooling1D(pool_size=pool_size, strides=pool_strides, padding='valid')\n",
    "        self.flatten = tf.keras.layers.Flatten()   \n",
    "        \n",
    "    def call(self, inputs, training, mask, attention_mask, pool_mask):\n",
    "        x = inputs\n",
    "        x = self.transformer_enc(x, training, mask, attention_mask)\n",
    "        for i in range(self.n2):\n",
    "            x = self.lstm[i](x)  \n",
    "        x *= pool_mask\n",
    "        x = self.max_pool(x)\n",
    "        x = self.flatten(x)   \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test\n",
    "# temp = TransLSTM(n1=1, d_model=32, num_heads=2, dff=10, input_vocab_size=60, maximum_position_encoding=60, weights=None,\n",
    "#                                             n2=1, lstm_dims=32,\n",
    "#                                             pool_size=2, pool_strides=2,\n",
    "#                                             rate=0.1)\n",
    "\n",
    "# y = tf.random.uniform((1, 60))  # (batch_size, encoder_sequence, d_model)\n",
    "# out = temp(y, training=False, mask=None, attention_mask=None, pool_mask=tf.ones((1,60,1)))\n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, n1, n2, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding,\n",
    "                 pool_size=2, pool_strides=1, rate=0.1, weights=None,\n",
    "                 lstm_dims=32,\n",
    "                 dim1=64, dim2=32, num_class1=10, num_class2=2):\n",
    "        '''\n",
    "         n1: number of layers in transformer encoder;\n",
    "         n2: number of layers in lstm;\n",
    "         d_model: dimension of embedding;\n",
    "         num_heads: number of heads in multi-head attention;\n",
    "         dff: dimension of feed forward innner layer;\n",
    "         input_vocab_size: vocab size;\n",
    "         max_position_encoding: ;\n",
    "         rate: dropout rate;\n",
    "         weights: pre-trained embedding weights;\n",
    "        '''\n",
    "        super(MyModel, self).__init__()\n",
    "        self.transLSTM = []\n",
    "        if weights is None:\n",
    "            for i, _ in enumerate(COLS_NAME):\n",
    "                self.transLSTM.append(TransLSTM(n1, d_model, num_heads, dff, input_vocab_size[i], maximum_position_encoding[i], weights,\n",
    "                                                n2, lstm_dims,\n",
    "                                                pool_size, pool_strides,\n",
    "                                                rate))\n",
    "        else:\n",
    "            for i, _ in enumerate(COLS_NAME):\n",
    "                self.transLSTM.append(TransLSTM(n1, d_model, num_heads, dff, input_vocab_size[i], maximum_position_encoding[i], weights[i],\n",
    "                                                n2, lstm_dims,\n",
    "                                                pool_size, pool_strides,\n",
    "                                                rate))            \n",
    "        \n",
    "        self.concat = tf.keras.layers.Concatenate(axis=-1)\n",
    "        self.dense1 = tf.keras.layers.Dense(dim1, activation='relu', name='dense1')\n",
    "        self.dense2 = tf.keras.layers.Dense(dim2, activation='relu', name='dense2')\n",
    "        self.dense3_age = tf.keras.layers.Dense(num_class1, activation='softmax', name='softmax1')\n",
    "        self.dense_gender = tf.keras.layers.Dense(num_class2, activation='softmax', name='softmax2')\n",
    "\n",
    "    def call(self, x, training, mask, attention_mask, pool_mask):\n",
    "        res = []\n",
    "        for i, layer in enumerate(self.transLSTM):\n",
    "            res.append(layer(x[i], training, mask, attention_mask, pool_mask))\n",
    "\n",
    "        x = self.concat(res)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3_age(x), self.dense_gender(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(n1=n1, n2=n2, d_model=d_model, num_heads=num_heads, dff=dff, \n",
    "                input_vocab_size=vocab_sizes, maximum_position_encoding=vocab_sizes, \n",
    "                weights=wv_matrixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test\n",
    "# model((tf.random.uniform((1, 60)), \n",
    "#        tf.random.uniform((1, 60)), \n",
    "#        tf.random.uniform((1, 60)), \n",
    "#        tf.random.uniform((1, 60))), \n",
    "#       training=False,\n",
    "#       mask=tf.random.uniform((1, 1, 1, 60)),       \n",
    "#       attention_mask=tf.random.uniform((1, 1, 1, 60)),\n",
    "#       pool_mask=tf.random.uniform((1,60,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数和metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    pred_age = pred[0]\n",
    "    real_age = real[0]\n",
    "\n",
    "    pred_gender = pred[1]\n",
    "    real_gender = real[1]\n",
    "\n",
    "    loss1 = loss_object(real_age, pred_age)\n",
    "    loss2 = loss_object(real_gender, pred_gender)\n",
    "\n",
    "    loss_ = 0.5*loss1 + 0.5*loss2\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "### train metric\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "age_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "gender_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "### test metric\n",
    "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
    "age_valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n",
    "gender_valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "\n",
    "    mask = create_padding_mask(inp[0])\n",
    "    attention_mask = tf.cast(inp[-1][:, tf.newaxis, tf.newaxis, :], tf.float32)\n",
    "    pool_mask = create_pooling_mask(inp[0])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inp, \n",
    "                            training=False, \n",
    "                            mask=mask, \n",
    "                            attention_mask=attention_mask,\n",
    "                            pool_mask=pool_mask\n",
    "                            )\n",
    "        loss = loss_function(tar, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    age_train_accuracy(tar[0], predictions[0])\n",
    "    gender_train_accuracy(tar[1], predictions[1])\n",
    "    return loss \n",
    "\n",
    "@tf.function\n",
    "def valid_step(inp, tar):\n",
    "\n",
    "    mask = create_padding_mask(inp[0])\n",
    "    attention_mask = tf.cast(inp[-1][:, tf.newaxis, tf.newaxis, :], tf.float32)\n",
    "    pool_mask = create_pooling_mask(inp[0])\n",
    "\n",
    "    predictions = model(inp, \n",
    "                        training=False, \n",
    "                        mask=mask, \n",
    "                        attention_mask=attention_mask,\n",
    "                        pool_mask=pool_mask\n",
    "                        )\n",
    "    loss = loss_function(tar, predictions)\n",
    "\n",
    "    valid_loss(loss)\n",
    "    age_valid_accuracy(tar[0], predictions[0])\n",
    "    gender_valid_accuracy(tar[1], predictions[1])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.4927 Age-Accuracy 0.1250 Gender-Accuracy 0.5000 Time taken for training: 2.544782876968384 secs\n",
      "Epoch 1 Batch 100 Loss 1.2898 Age-Accuracy 0.2021 Gender-Accuracy 0.7806 Time taken for training: 192.59902548789978 secs\n",
      "Epoch 1 Batch 200 Loss 1.1810 Age-Accuracy 0.2424 Gender-Accuracy 0.8381 Time taken for training: 191.30518531799316 secs\n",
      "Epoch 1 Batch 300 Loss 1.1082 Age-Accuracy 0.2707 Gender-Accuracy 0.8629 Time taken for training: 189.51898741722107 secs\n",
      "Epoch 1 Batch 400 Loss 1.0588 Age-Accuracy 0.2915 Gender-Accuracy 0.8753 Time taken for training: 190.8416042327881 secs\n",
      "Epoch 1 Batch 500 Loss 1.0233 Age-Accuracy 0.3067 Gender-Accuracy 0.8841 Time taken for training: 190.17677426338196 secs\n",
      "Epoch 1 Batch 600 Loss 0.9991 Age-Accuracy 0.3176 Gender-Accuracy 0.8894 Time taken for training: 189.46304559707642 secs\n",
      "Epoch 1 Batch 700 Loss 0.9796 Age-Accuracy 0.3270 Gender-Accuracy 0.8940 Time taken for training: 193.56990027427673 secs\n",
      "Epoch 1 Batch 800 Loss 0.9640 Age-Accuracy 0.3346 Gender-Accuracy 0.8976 Time taken for training: 191.54317593574524 secs\n",
      "Epoch 1 Batch 900 Loss 0.9508 Age-Accuracy 0.3414 Gender-Accuracy 0.9005 Time taken for training: 191.10484075546265 secs\n",
      "Epoch 1 Batch 1000 Loss 0.9397 Age-Accuracy 0.3470 Gender-Accuracy 0.9029 Time taken for training: 192.21958875656128 secs\n",
      "Epoch 1 Batch 1100 Loss 0.9312 Age-Accuracy 0.3513 Gender-Accuracy 0.9047 Time taken for training: 193.69254446029663 secs\n",
      "Epoch 1 Batch 1200 Loss 0.9219 Age-Accuracy 0.3560 Gender-Accuracy 0.9066 Time taken for training: 192.60392880439758 secs\n",
      "Epoch 1 Batch 1300 Loss 0.9141 Age-Accuracy 0.3604 Gender-Accuracy 0.9081 Time taken for training: 194.03648328781128 secs\n",
      "Epoch 1 Batch 1400 Loss 0.9077 Age-Accuracy 0.3636 Gender-Accuracy 0.9093 Time taken for training: 199.50014686584473 secs\n",
      "Epoch 1 Batch 1500 Loss 0.9019 Age-Accuracy 0.3667 Gender-Accuracy 0.9104 Time taken for training: 201.18534016609192 secs\n",
      "Epoch 1 Batch 1600 Loss 0.8969 Age-Accuracy 0.3695 Gender-Accuracy 0.9113 Time taken for training: 198.2931046485901 secs\n",
      "Epoch 1 Batch 1700 Loss 0.8918 Age-Accuracy 0.3722 Gender-Accuracy 0.9123 Time taken for training: 199.97610425949097 secs\n",
      "Epoch 1 Batch 1800 Loss 0.8871 Age-Accuracy 0.3746 Gender-Accuracy 0.9131 Time taken for training: 197.95492362976074 secs\n",
      "Epoch 1 Batch 1900 Loss 0.8830 Age-Accuracy 0.3770 Gender-Accuracy 0.9139 Time taken for training: 199.89768409729004 secs\n",
      "Epoch 1 Batch 2000 Loss 0.8789 Age-Accuracy 0.3791 Gender-Accuracy 0.9146 Time taken for training: 197.0091826915741 secs\n",
      "Epoch 1 Batch 2100 Loss 0.8755 Age-Accuracy 0.3811 Gender-Accuracy 0.9152 Time taken for training: 200.07339310646057 secs\n",
      "Epoch 1 Batch 2200 Loss 0.8723 Age-Accuracy 0.3827 Gender-Accuracy 0.9160 Time taken for training: 196.77118515968323 secs\n",
      "Epoch 1 Batch 2300 Loss 0.8695 Age-Accuracy 0.3843 Gender-Accuracy 0.9165 Time taken for training: 190.1802225112915 secs\n",
      "Epoch 1 Batch 2400 Loss 0.8667 Age-Accuracy 0.3858 Gender-Accuracy 0.9170 Time taken for training: 193.65362238883972 secs\n",
      "Epoch 1 Batch 2500 Loss 0.8641 Age-Accuracy 0.3872 Gender-Accuracy 0.9175 Time taken for training: 193.85889625549316 secs\n",
      "Epoch 1 Batch 2600 Loss 0.8615 Age-Accuracy 0.3887 Gender-Accuracy 0.9180 Time taken for training: 194.02130436897278 secs\n",
      "Epoch 1 Batch 2700 Loss 0.8594 Age-Accuracy 0.3898 Gender-Accuracy 0.9184 Time taken for training: 198.25208067893982 secs\n",
      "Epoch 1 Batch 2800 Loss 0.8574 Age-Accuracy 0.3909 Gender-Accuracy 0.9187 Time taken for training: 229.57547855377197 secs\n",
      "Executing op __inference_train_step_97531 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "########################################## valid ################################################\n",
      "Epoch 1 Batch 2812 Loss 1.1854 Age-Accuracy 0.2481 Gender-Accuracy 0.6327           Time taken for validation: 363.1183977127075 secs\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    age_train_accuracy.reset_states()\n",
    "    gender_train_accuracy.reset_states()\n",
    "\n",
    "    '''\n",
    "    inp1: ad_id list;\n",
    "    inp2: product_id list;\n",
    "    inp3: advertiser_id list;\n",
    "    inp4: click_times list;\n",
    "    '''\n",
    "    for (batch, (inp1, inp2, inp3, inp4, tar)) in enumerate(tr_ds):\n",
    "        train_step((inp1, inp2, inp3, inp4), tar)\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Age-Accuracy {:.4f} Gender-Accuracy {:.4f} Time taken for training: {} secs'\n",
    "                   .format(epoch + 1, batch, train_loss.result(), \n",
    "                           age_train_accuracy.result(), gender_train_accuracy.result(),\n",
    "                          time.time()-start))\n",
    "            start = time.time()\n",
    "            \n",
    "    tmp = time.time()\n",
    "    for inp1, inp2, inp3, inp4, tar in vl_ds:\n",
    "        valid_step((inp1, inp2, inp3, inp4), tar)    \n",
    "    print('########################################## valid ################################################')\n",
    "    print('Epoch {} Batch {} Loss {:.4f} Age-Accuracy {:.4f} Gender-Accuracy {:.4f} \\\n",
    "          Time taken for validation: {} secs'\n",
    "          .format(epoch + 1, batch, \n",
    "                  valid_loss.result(), age_valid_accuracy.result(), gender_valid_accuracy.result(),\n",
    "                  time.time() - tmp))\n",
    "    \n",
    "       \n",
    "#         if (epoch + 1) % 5 == 0:\n",
    "#             ckpt_save_path = ckpt_manager.save()\n",
    "#             print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "#                                                                  ckpt_save_path))\n",
    "\n",
    "#             print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "#                                                         train_loss.result(), \n",
    "#                                                         train_accuracy.result()))\n",
    "\n",
    "#             print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
