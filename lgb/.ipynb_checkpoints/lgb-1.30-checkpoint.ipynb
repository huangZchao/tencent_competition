{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from config import *\n",
    "import pandas as pd\n",
    "from tools import *\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "\n",
    "from multiprocessing import Pool \n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_user_log = pd.read_pickle(TRAIN_DIR+USER_LOG_PATH)\n",
    "tr_ad_info = pd.read_pickle(TRAIN_DIR+AD_INFO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_user_log = pd.read_pickle(TEST_DIR+USER_LOG_PATH)\n",
    "ts_ad_info = pd.read_pickle(TEST_DIR+AD_INFO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### target\n",
    "AGE = tr_user_log.groupby(['user_id'])['age'].agg('first')\n",
    "GENDER = tr_user_log.groupby(['user_id'])['gender'].agg('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tr_user_log['creative_id'].values.tolist() == tr_ad_info['creative_id'].values.tolist()\n",
    "grid_df = pd.concat([tr_user_log, tr_ad_info[['ad_id', 'product_id', 'product_category', 'advertiser_id', 'industry']]], axis=1)\n",
    "assert ts_user_log['creative_id'].values.tolist() == ts_ad_info['creative_id'].values.tolist()\n",
    "grid_df_test = pd.concat([ts_user_log, ts_ad_info[['ad_id', 'product_id', 'product_category', 'advertiser_id', 'industry']]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 点击每天特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_clk_time_per_day = tr_user_log.groupby(['user_id', 'time']).agg({'click_times': np.sum}).reset_index()\n",
    "tr_clk_time_per_day = pd.pivot_table(tr_clk_time_per_day, index='user_id', columns='time', values='click_times')\n",
    "tr_clk_time_per_day.columns = ['time_'+str(col) for col in tr_clk_time_per_day.columns]\n",
    "\n",
    "tr_clk_time_per_day = tr_clk_time_per_day.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_clk_time_per_day.to_pickle(TRAIN_DIR+'per_day_click.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_clk_time_per_day = ts_user_log.groupby(['user_id', 'time']).agg({'click_times': np.sum}).reset_index()\n",
    "ts_clk_time_per_day = pd.pivot_table(ts_clk_time_per_day, index='user_id', columns='time', values='click_times')\n",
    "ts_clk_time_per_day.columns = ['time_'+str(col) for col in ts_clk_time_per_day.columns]\n",
    "\n",
    "ts_clk_time_per_day = ts_clk_time_per_day.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_clk_time_per_day.to_pickle(TEST_DIR+'per_day_click.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-fold Target Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=N_SPLITS, shuffle=True, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_kfold = grid_df.groupby(['user_id']).agg('first').reset_index()\n",
    "for fold_,(trn_idx,val_idx) in enumerate(folds.split(user_kfold, user_kfold)):\n",
    "    user_kfold.loc[val_idx, 'fold'] = fold_\n",
    "\n",
    "user_kfold = user_kfold[['user_id', 'fold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_grid_df = grid_df.merge(user_kfold, on=['user_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### kfold split target encode\n",
    "##############################\n",
    "def target_encode_df(tr_df, vl_df, feat, label='age', value='click_times'):\n",
    "    if label == 'age':\n",
    "        col_cnt = 10\n",
    "    else:\n",
    "        col_cnt = 2\n",
    "    def target_encode(df, feat, label='age', value='click_times'):\n",
    "        temp = df.groupby([feat, label]).agg({value: np.sum})\n",
    "        temp_pcts = temp.groupby(level=0).apply(lambda x: x / float(x.sum()))\n",
    "        temp_pcts = temp_pcts.unstack(level=1)\n",
    "        temp_pcts = temp_pcts.droplevel(level=0, axis=1)\n",
    "        temp_pcts.columns= [feat+\"_\"+label+'_rate'+str(i) for i in temp_pcts.columns]\n",
    "        return temp_pcts\n",
    "\n",
    "    temp_pcts = target_encode(tr_df, feat, label, value)\n",
    "    temp_pcts = vl_df[['user_id', feat, value]].merge(temp_pcts, on=[feat], how='left').fillna(0)\n",
    "    \n",
    "    for i in range(1, col_cnt+1):\n",
    "        temp_pcts[feat+\"_\"+label+'_rate'+str(i)] = temp_pcts[feat+\"_\"+label+'_rate'+str(i)] * temp_pcts[value]\n",
    "        \n",
    "    del temp_pcts[feat], temp_pcts[value]\n",
    "    return temp_pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get kfold target encode dataframe\n",
    "##############################\n",
    "def get_te_df(feat):\n",
    "    te_dfs = []\n",
    "\n",
    "    for i in range(N_SPLITS):\n",
    "        tr_df = kfold_grid_df[kfold_grid_df['fold']!=i]\n",
    "        vl_df = kfold_grid_df[kfold_grid_df['fold']==i]\n",
    "\n",
    "        vl_df = target_encode_df(tr_df, vl_df, feat=feat)\n",
    "        mean = vl_df.groupby(['user_id']).mean()\n",
    "        mean.columns = [col+'_mean' for col in mean.columns]\n",
    "        \n",
    "        median = vl_df.groupby(['user_id']).median()\n",
    "        median.columns = [col+'_median' for col in median.columns]\n",
    "        \n",
    "        m = vl_df.groupby(['user_id']).max()\n",
    "        m.columns = [col+'_max' for col in m.columns]\n",
    "        \n",
    "        std = vl_df.groupby(['user_id']).std()\n",
    "        std.columns = [col+'_std' for col in std.columns]\n",
    "\n",
    "        te_dfs.append(pd.concat([mean, median, m, std], axis=1).reset_index())\n",
    "    te_df = pd.concat(te_dfs, axis=0).sort_values(by=['user_id']).set_index('user_id')\n",
    "    del te_dfs\n",
    "    return te_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(5)\n",
    "t_split = ['time', 'product_id', 'product_category', 'advertiser_id', 'industry']\n",
    "dfs = pool.map(get_te_df, t_split)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_df = pd.concat(dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_df.to_pickle(TRAIN_DIR+'kfold_te.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test set\n",
    "##################################\n",
    "def target_encode_test(feat):\n",
    "    te_df = target_encode_df(grid_df, grid_df_test, feat=feat)\n",
    "    mean = te_df.groupby(['user_id']).mean()\n",
    "    mean.columns = [col+'_mean' for col in mean.columns]\n",
    "\n",
    "    median = te_df.groupby(['user_id']).median()\n",
    "    median.columns = [col+'_median' for col in median.columns]\n",
    "\n",
    "    m = te_df.groupby(['user_id']).max()\n",
    "    m.columns = [col+'_max' for col in m.columns]\n",
    "\n",
    "    std = te_df.groupby(['user_id']).std()\n",
    "    std.columns = [col+'_std' for col in std.columns]\n",
    "\n",
    "    return pd.concat([mean, median, m, std], axis=1).reset_index().sort_values(by=['user_id']).set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(5)\n",
    "t_split = ['time', 'product_id', 'product_category', 'advertiser_id', 'industry']\n",
    "dfs = pool.map(target_encode_test, t_split)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_df_test = pd.concat(dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_df_test.to_pickle(TEST_DIR+'kfold_te.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 序列统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## statistic feature\n",
    "##########################\n",
    "def get_nunique_feat(df, main_key, col):\n",
    "    return df.groupby([main_key])[col].agg('nunique').rename(col+'_nunique')\n",
    "\n",
    "def get_count_feat(df, main_key, col):\n",
    "    return df.groupby([main_key])[col].agg('count').rename('log_cnt')\n",
    "\n",
    "def get_sum_mean_max_min_std_feat(df, main_key, col):\n",
    "    postfix = ['sum', 'mean','max','min','std']\n",
    "    for i in range(len(postfix)):\n",
    "        if i == 0:\n",
    "            temp = df.groupby([main_key])[[col]].agg(postfix[i]).rename(columns={col: col+'_'+postfix[i]})\n",
    "        else:\n",
    "            temp[col+'_'+postfix[i]] = df.groupby([main_key])[col].agg(postfix[i])\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "feature_columns = ['creative_id', 'time', 'ad_id', 'product_id' ,'product_category', 'advertiser_id', 'industry']\n",
    "for col in feature_columns:\n",
    "    dfs.append(get_nunique_feat(grid_df, 'user_id', col))\n",
    "    \n",
    "dfs.append(get_count_feat(grid_df, 'user_id', 'creative_id'))\n",
    "dfs.append(get_sum_mean_max_min_std_feat(grid_df, 'user_id', 'click_times'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_statistic_df = pd.concat(dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_statistic_df.to_pickle(TRAIN_DIR+'seq_statistic.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test set\n",
    "#################################\n",
    "dfs = []\n",
    "feature_columns = ['creative_id', 'time', 'ad_id', 'product_id' ,'product_category', 'advertiser_id', 'industry']\n",
    "for col in feature_columns:\n",
    "    dfs.append(get_nunique_feat(grid_df_test, 'user_id', col))\n",
    "    \n",
    "dfs.append(get_count_feat(grid_df_test, 'user_id', 'creative_id'))\n",
    "dfs.append(get_sum_mean_max_min_std_feat(grid_df_test, 'user_id', 'click_times'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_statistic_df_test = pd.concat(dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_statistic_df_test.to_pickle(TEST_DIR+'seq_statistic.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 两两交叉统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 'age',\n",
       " 'gender',\n",
       " 'time',\n",
       " 'creative_id',\n",
       " 'click_times',\n",
       " 'ad_id',\n",
       " 'product_id',\n",
       " 'product_category',\n",
       " 'advertiser_id',\n",
       " 'industry']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROSS_FEATURES = grid_df.columns.tolist()\n",
    "CROSS_FEATURES.remove('user_id')\n",
    "CROSS_FEATURES.remove('age')\n",
    "CROSS_FEATURES.remove('gender')\n",
    "CROSS_FEATURES.remove('click_times')\n",
    "CROSS_FEATURES.remove('creative_id')\n",
    "CROSS_FEATURES.remove('ad_id')\n",
    "\n",
    "for i in tqdm(range(len(CROSS_FEATURES)-1)):\n",
    "    feat1 = CROSS_FEATURES[i]\n",
    "    for feat2 in tqdm(CROSS_FEATURES[i+1:]):\n",
    "        col_name = feat1+\"_\"+feat2\n",
    "        grid_df[col_name] = grid_df[feat1].astype(str).values + '_' + grid_df[feat2].astype(str).values\n",
    "        grid_df_ts[col_name] = grid_df_ts[feat1].astype(str).values + '_' + grid_df_ts[feat2].astype(str).values\n",
    "\n",
    "dfs1 = []\n",
    "dfs2 = []\n",
    "cf_feat = [ 'time_product_id',\n",
    " 'time_product_category',\n",
    " 'time_advertiser_id',\n",
    " 'time_industry',\n",
    " 'product_id_product_category',\n",
    " 'product_id_advertiser_id',\n",
    " 'product_id_industry',\n",
    " 'product_category_advertiser_id',\n",
    " 'product_category_industry',\n",
    " 'advertiser_id_industry']\n",
    "\n",
    "for feat in cf_feat:\n",
    "    dfs1.append(get_nunique_feat(grid_df, 'user_id', feat))\n",
    "    dfs2.append(get_nunique_feat(grid_df_test, 'user_id', feat))\n",
    "cf_df = pd.concat(dfs1, axis=1)\n",
    "cf_df_ts = pd.concat(dfs2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([tr_clk_time_per_day, seq_statistic_df, kfold_df, AGE], axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([ts_clk_time_per_day, seq_statistic_df_test, kfold_df_test], axis=1).reset_index()\n",
    "test_user = test_df[['user_id']]\n",
    "del test_df['user_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred), \"length of y_true and y_pred not equal\"\n",
    "    total_example = len(y_true)\n",
    "    right_cnt = 0\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        if t == p:\n",
    "            right_cnt += 1\n",
    "    return right_cnt / total_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'age'\n",
    "\n",
    "FEATURE_COLUMNS = train_df.columns.tolist()\n",
    "FEATURE_COLUMNS.remove('user_id')\n",
    "FEATURE_COLUMNS.remove(TARGET)\n",
    "\n",
    "X_train, y_train = train_df[FEATURE_COLUMNS], train_df[TARGET]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = { \n",
    "    'boosting_type': 'gbdt',  \n",
    "    'objective': 'multiclass',  \n",
    "    'num_class': 10,  \n",
    "    'metric': ['multi_error'],  \n",
    "    'num_leaves': 2**9,  \n",
    "    'min_data_in_leaf': 500,  \n",
    "    'learning_rate': 0.1,  \n",
    "    'feature_fraction': 0.8,  \n",
    "    'bagging_fraction': 0.8,  \n",
    "    'bagging_freq': 5,  \n",
    "    'lambda_l1': 0.4,  \n",
    "    'lambda_l2': 0.5,  \n",
    "    'min_gain_to_split': 0.2,  \n",
    "    'verbose': -1,\n",
    "    'num_threads':6,\n",
    "    'n_estimators': 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=N_SPLITS, shuffle=True, random_state=np.random.randint(2020))\n",
    "# 五折交叉验证\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx], y_train[val_idx])\n",
    "\n",
    "    clf = lgb.train(param, \n",
    "                    trn_data, \n",
    "                    valid_sets = [trn_data, val_data], \n",
    "                    verbose_eval = 100, \n",
    "                    early_stopping_rounds = 200)\n",
    "    \n",
    "    y_val_pred = clf.predict(X_train.iloc[val_idx])\n",
    "    y_val_pred = np.argmax(y_val_pred,axis=-1).tolist()\n",
    "    acc = accuracy(y_train[val_idx].values.tolist(), y_val_pred)\n",
    "    print(\"kfold: {:d}, accuracy: {:.4f}\".format(fold_+1, acc))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = '/home/huangzc/competition/tencent/model_ckpt/lgb/model.txt'\n",
    "clf.save_model(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.Booster(model_file=SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_age = clf.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_age = np.argmax(predicted_age, axis=-1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user['predicted_age'] = pd.Series(predicted_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user.to_csv(SUBMISSION_AGE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "competition-py36",
   "language": "python",
   "name": "competition-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
